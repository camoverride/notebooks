{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Model\n",
    "A simple model that predicts a person's emotional state. This uses [VGG16](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16\n",
    ") for the earlier layers of the model and applies a custom (3 layer) network on top. I would like to predict 4 classes: happy, angry, sad, and scared/surprised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README      fer2013.bib fer2013.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Show where the data is stored.\n",
    "! ls ../data/face_data/fer2013/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/face_data/fer2013/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      "emotion    35887 non-null int64\n",
      "pixels     35887 non-null object\n",
      "Usage      35887 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three columns. \"Usage\" seems to be a pre-defined train/test split, probably balanced by gender/race/age.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    8989\n",
       "6    6198\n",
       "4    6077\n",
       "2    5121\n",
       "0    4953\n",
       "5    4002\n",
       "1     547\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 7 types of emotion. This is more than I care about and I will change them later.\n",
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PublicTest      3589\n",
       "PrivateTest     3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are two types of \"Test\" -- I'll combine them together.\n",
    "df.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a numpy array.\n",
    "dfx = np.array(df)\n",
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The photos are stored as a string -- convert it  to list of integers.\n",
    "for i in range(len(dfx)):\n",
    "    dfx[i][1] = np.array([int(x) for x in dfx[i][1].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/validation/test split.\n",
    "dfx_train = dfx[dfx[:, 2] == \"Training\"]\n",
    "dfx_val = dfx[dfx[:, 2] == \"PrivateTest\"]\n",
    "dfx_test = dfx[dfx[:, 2] == \"PublicTest\"]\n",
    "\n",
    "X_train, y_train = dfx_train[:, 1],  dfx_train[:, 0]\n",
    "X_val, y_val = dfx_val[:, 1],  dfx_val[:, 0]\n",
    "X_test, y_test = dfx_test[:, 1], dfx_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many pixels are in each image?\n",
    "len(dfx[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the dimensions of the picture (assuming its a square)?\n",
    "np.sqrt(2304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1174b84a8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2da6xlZ3nf/89ee+3bud9m5szNc/HYXIwxMKFOSUpqICIExXygSgBVbuuKL60EStpgWqlqpFaCL5APrVJZBcWVopgkpDKhRJFFcLiUAgM2YDPY47l47mfO/bLve623H862medyzt4ez+w5Zj0/aTTzvufd73rX5d3rPP95LhRCgOM4v/zkbvcCHMcZDL7ZHScj+GZ3nIzgm91xMoJvdsfJCL7ZHScjvKbNTkTvJ6LniehFInrkZi3KcZybD93o/7MTUQTgBQDvA3ARwA8AfCSE8LOtPhMND4X85CTvFIcnYzlBfiXlUzUmziesXc631Zg88c/FlKgxsi+CPpZaX88Rm+TEyZHxyU6IRFt/H7dCnrfTvBrTTvk8rSRSY9KUtl5sl1xOr1GeR5LqNcrHiox5ChG/1kP5lhpTJH4f5T0E9HXcSEtqzEqzzNpxpO+9dR7y/CPj+K2EX3/rugbRZ10PEtc1TYx3ccLnyYnHvL26hE6tat5Y/ZT0zzsBvBhCOLO5UHocwIMAttzs+clJzP77T2672Fxbr7MzxC9wbrqpxuyeXGPtt05dVmMm4yprzxZW1Jg9+VXWHsnV1RhJavyClECfx0iuwdrWF8liMszaS6INAGebM6x9uTGuxlyqjbH2xdUxNaZWK7K2fCABYHi4ofqKcYe116p6c3Xa/NEqFPWX78HJZdY+PnlejbmzNMfak9GGGiM34HfW71Jj/ubcPay9b2xVjVmsDam+4SJ/1iaKNTXm7PIUazdasRrTrBZYu1DRX2x58RKrrurrmlvhc1eu8GfvzGOfU5955bNb/qQ3+wBcuK59sdvnOM4O5LVsdutXBfW7CRF9nIhOENGJZKNqfMRxnEHwWjb7RQAHrmvvB6B+dw4hPBpCOB5COB4N61+THMcZDK/FZv8BgGNEdBjAJQC/B+Cj2x6s1MGuYwusb73O7cbaQkV9jlr8O8myLVdrXIB5lmbVmF2VddZeKukvn2uFUdaezmsbUZIzRBtL/CtQp+eYpQ630efao2rMuRq3ES9VtT2+WOXXUdrnAJBUhW1paJFrda0ZRGtc7IvXDWGrxH/Jq0/pR+2sEKCkqAgAGxN83W+qaC1GXtfhSGs6o2WuPdTaBTWmHGtdQQqb1bZxHQN/HksFPU9jmdvfzaa2x9uVjuqTpCV+k2p7xM+32dE3vNlDCB0i+rcA/g5ABOCLIYTnbnQ+x3FuLa/lzY4QwtcAfO0mrcVxnFuIe9A5TkZ4TW/2V8twvon7d59jfQtNbhO+WJ5Wn7t2jdukYVnbW7VFYftPaNtqcYjbsRfL+v+nhwr8/z/3Den/ix8Wzh/7i8tqzHS8rvqkM8x8Z0SNudDgTkdXG9pmv1rlfSt1bf9JG13Z5wCozr/rc0393V+e1/pIcVk4B3W0g0gqblHnqj5+fRe/HmfWjfva5p+rT+l5ZgpcVxmJtG/A0TGuFZ1c3KPG7B7W92xN2NZrLf1cdTrcri+WDOegcb6m5lJZjaGr/FhU0SJKEI43IZbeS+ojr+BvdsfJCL7ZHScj+GZ3nIzgm91xMsJABbpOiJQgd3GDi2QrG1q4CG3+nRQ19HdUXsSrJE0tpNRG+OnWCoZIEnNRZG1Si1+zIzzoZjyvgyMsga6ZcnHpbH1GjTm9xgXK5YZeY0MEmUiBCABScc1K41q0apX5PLmL+lwTrZmhPi2cSJa0QKeC9QzhqLTIOwtr+mBzVX6N/n5Gi5r7prmIun9Yi6oNEZkW5bT4VTUcbSSx8TkZGCSj1zb75Ie0Q1VuRQh9F/V9rR0SDjtJ78jFV+bve6TjOK9rfLM7Tkbwze44GWGgNvtGs4DvnjnM+tIGt0sKV7TTRLkp7BIjNYw0k8iMKeDHSsqWvcPHLCTaRpTcM6qDM/bktd14uT3B2tcaOsjk6jo/Xqutb5HMApMYNvvUFHc0OTCqHX+eOXeAtVPpoAEgjfU1SkaFY0dejynN8zH5mp57gx8eJcOBZ/znvG+jrjWMlzb4MzM3oe/ZcJkHx9Sa+jmTmXMAnfHIsvWtPonM7tNY1ZqSkZRIkV/mz0OyRzjwRFvnTfI3u+NkBN/sjpMRfLM7Tkbwze44GWGgAh3aOeQuc8eN4ctcgCnPG2KHEDdaw1rIiYRO0TbGtCZEtJblkCD1jZq+ROsiomyfEfX2lsI11VdL+edGYp1RJS9EIkugk4JcXNBq5GSZO/r8+Px+NSa+wNdTvmpkALpXZ12hAl9jWtDOKPV9/D4WFrSIOPISb28cMJxROnxNRqIabMR87gZp56DGCu/LlfQ1a5X1/ZACnRTarL6hWEe9FXL8mi0aWWmSmrxG+prJKMSm8HoiIzvzK+vc8ieO4/xS4ZvdcTKCb3bHyQgDtdnzdWBC1IuJa9y2S7SvAzpFbockJcO2vEtUjTGcamQy17Bb22g0J5wdWvpY7Ra/bLKKDACM5/T3aCPwkztUXlRjqhPcBvv5wi41ptXkx5elrwDtnIN57cQRr/NzC+/R2gOt6Gy/wz/m9m9b+wYhX+PnP/SA1jDmRCmw8ef049gRCYAbU2oIIEsrGYFSIc/t6rioH5A06Hsty29RemPl0oaEPiODdwDgQsKdrpIVrT3k6yJ4aFmc+zYJav3N7jgZwTe742QE3+yOkxF8sztORhisUw2gnFbqk1xg6AxpkaS+W0RQGRWZisv8e6t+UDuDqFrwRkrqwh28+GT7vC4RlRdOLDP5NTVm3hByZLmn1EjfckdlibXXRrVI88Iaj/yyJCOZvSaSkYMA6m/m6X1+ddcVNebk375R9Y2d5U4jaWTMPc0frbnzk2rMHXdy0W7u6l41RvorbRzRClRpip9H85oWFSVW7fN+ot4spxr5uYKhDk8V+XNVyevnc1WkBF8b0aJqXpRe7ycj0Mv4m91xMoJvdsfJCL7ZHScjDNRmpxQoVLnzy+ox/n3T2qcdXSqnRGmnY3oMOiID7Yo+tXSX+FxJ22gqC8yYtr9+/eA51p7K1dWY+URnVGkHkT3U8ICYLnJB4qWCtnV3z3AnnplKVY05dY1nZe0YpYTuPcijSmod7dG0dlh1Ye0wH9eZsjw5eN/4Lp1tt5Pye9a8U2fAbYgsuZO7tD4yUuQawvmqkSVWBNQUS9pmlsFDADBb5td6sak1nFLEz9Uq4Z0K43o81s/Msal51j6xrI8VrvG9kNOP8Jb4m91xMoJvdsfJCL7ZHScj+GZ3nIwwUIEujYGNvVykSo9wUWTs/2mHiPHTXExpv6iFpJWj/Hvrjt88p8acPM2dNkhlBgGGDnOB7J0HXlJjfnf6+6x9qaNrqM8num8l6e3sIblzaF71/as932btxUSHnX2Z3s7aew5pgezMOg8hk0ITALzvPU+rvkREh8n66ICukX6lNabG1EWI493jOjLuaIWfv1V7Xc69VNPiaCScYaQYBgD3jl5SfVJUXW71voe7i1bpL77V6kZdrV1CnJ2e0WJk9XkuvBZWZfalrdflb3bHyQi+2R0nI/Tc7ET0RSK6RkTPXtc3SURPEtGp7t8T283hOM7tpx+b/U8B/DcA/+u6vkcAfD2E8BkieqTb/lSvidK8zjTSWed2m1UmaP5ePiZoUxv1w9yxYras7Z3Ze3jfP5y5U4158/RV1v7A5E/VmEqOO+dcaOv0KS809qi+mrDThiPtHDQWcQeZsbJ2mJHHbxkX5DeneUqgiy3tnJMb4dd6VNa9BjAR6+OXhDPQpBGZNCIcjWZjnQUnFe+aHLQzylCO31eZ7cc6/sG7dAagRBzrLaULaoylqTxdO8TaMkssALRSfv2riQ5gGclrraEXlpPP0jS/RhOn+D20MjS98rNeBwwhfBPAkuh+EMBj3X8/BuBDveZxHOf2cqM2++4QwhUA6P6tE6U5jrOjuOUCHRF9nIhOENGJpKp/JXQcZzDc6GafI6JZAOj+rf+DtEsI4dEQwvEQwvFoSDv2O44zGG7UqeYrAB4C8Jnu30/086FAQFIUgoJwbFn6J1q0esMBLprdNaq/W2YLPDrJEoSk2PPRme+qMT9vcsebY4U5NaYauNB2tjmjxpyva0FMijTTsZFyR3Bf6WLPMeda06pPCnLTsXb0GMtrAUhSM8Sma8JhyHKYkcKezNIDAJMRP/8pQ+iLwT83BP18VEVZrT1FnaY5Evl8IkMMbAe9HSpCRD1qODkttrhTU7uPQuuWOCsdeCwnJxmF2RoS4vU2h+7nv97+HMB3AdxNRBeJ6GFsbvL3EdEpAO/rth3H2cH0fLOHED6yxY/ec5PX4jjOLcQ96BwnIww2U00xRe4wt+WGS9yOHilpW+bIMHeSOFrSdlMxx4NlZHlkADjd3M3HGMEI9w+fZu3xnC6/+0PhaLFg1D/KGTlfqx2+pkasHUSko4lVkkhmOP2V0nk1ZjXhYuiP1g+qMeWIX7OZgrbrLYrbeW50OVvnOsa4oQ+MlLiG0Uj1/RjPc/tbOscAwJ6IO0stpto5RjoeXe1oncGaW2aYsZ4ZiQy6AXTQj5WlVt7rQ8PaOQjHePNn80dYO3ly63X5m91xMoJvdsfJCL7ZHScj+GZ3nIwwUIEujhLMTnAxpSTK4DQTvaSfLHFHl29dOqLGdEQ5n4khHcH1q7vOsvaugo6MOxBzUeScIeRcaY2zthRfAKBqCDmW2CZpCceOcx0dUbc3vyza2mHlX449z9pWZNoT8/ex9smV3WpMPxwakXFSwBuGuCPU3SVdWkpGxpVIp3ceFxF+sZGm+YLIFHSp3Tvi2nKgkU4tgE4LLTPOWH3LLZ0pR9JJ9bEKwolmJK/F6r0V7jy29HZ+na9WjLJnXfzN7jgZwTe742QE3+yOkxF8sztORhioQJcEwnqTC1eXFrjYlSZaxIryXCTZNaE9vXZVeN/xce1Vdk+ZpyKKDLGnJKKzTnXG1RgZCWXV7bKQoowl9kiRaLFjeefxdc/kdBTgWJ6Lhh8b0d5YDw79H9Y+YzjGNQzRyvIq1GN4OzYKhzcCP48lQ7SSgpy1Hhn1tp5qgWy1w73qUmM9lkA33xph7QWj1ttai9dVt0TmIMRZWecO0F51taJOZSVF3lbC1xy2KdDub3bHyQi+2R0nI/hmd5yMMFCbvRAlODDKnQI6I9zWnizqPHX7SzzySWalAYCZ/Nq2bUBnobm/fFqNkVlGLEcPmUp5tqAzo1hlivpJJT2knEi0w4yM6FtNjfTKgdvVaaqjrBIRmXckr23WIun3QVukc06NrC9y7nbQY2TWcKmXWMwn2maeF0410j4HgNWE2/EyAnFzjfpcr9S5U1W1rZ2lVurcZm919LbK5/T5S6Q9virmBYCCcKBqdkQ5tdRtdsfJPL7ZHScj+GZ3nIzgm91xMsJABbrRfAPvm/nZtmOmIh2dJdMFSRELAGZEaqJzbZ3eWUZZVUh7kZSEE8c5Y40LwtFltaOdOCxhzarJLZFRb5bQmAghKTEcKdLA1a/YENqSwNfYCIYYaPTJmay5S8TPIzbSdNWIi4hVw9FkKeUilRTjAGBdjKkZ6a1kZOJCSwt9ecPJaq3J56629NyNFp+72dSCaRT1FuiSpPe7typEvLQt0phtM4e/2R0nI/hmd5yM4JvdcTLCYDPVUII9ee4QU+ojqEIynutdtuibq3epviPlBdb+ByPdtKx9ft4orXS6qvUAyWRBOweNx3zdFePcr7W5TWoFZ4xHfJ5G0DrHunCqGVEjtK1tOb7MGzagdD4Zy1nZUbitb1msi+L6W7XXpY2+ZgS5yBJVG0bJKulEI4NXAKBmOMzIwK1aQ8/davJtlDb0PUuEbY2c1jAg7HEq907ZHZpiXmPaVw7ZczbHcX4p8M3uOBnBN7vjZATf7I6TEQafqUY4QFSFA4SsoQ5oZxjLYeVUaw9rP3X2mBpzcpyPkdFKAFCrcQHGcoZo17mQFJe1QFUs6r7JCj+PX5l+SY2R6a3PN3Uq6UvgqZJLQ70j86qGA5HM1FMy6o9ZkWDXEu5UtJj2rnUus+sAWpCz6vOtJDyCba6tU3svtrmDzLWmliPnaryvYUSmrRvPQ73a2xEqbXFBjppGSupG7zTi8lKn/WxPectcoHMcxze742QE3+yOkxEGarOnyGFdZAyRTixtI/BC1iyXdj8AvNDg9jg9rwMdLuzinyMjk21+XQSZaPMLstpS+ZK2NUtLhoPKQW5r/++36My19+6/xNpvGJlTY6SNeqalnXxiYaNbGXfkdZ2JdNbeFcOJZUnY7FZdc0nDyKYjudLW10MG/VgOM5dFNpnFhpEBVjjDNNt6Pe22vtmhj+AUdPhzlKvr54rkGCspj7C3EyMwSCYkVv5MnqnGcRzf7I6TEXyzO05G6LnZiegAEX2DiE4S0XNE9Ilu/yQRPUlEp7p/966T6zjObaMfga4D4A9CCD8iohEAPySiJwH8CwBfDyF8hogeAfAIgE/1mkzWu5ZRXVbk06IQhCLDQeNyg4s7xSUtVORkdFJReyBEwvnBqNCEvd/momLxp7rUVDI/r/omhrhwtPC796oxz7z7AGu/NKm/Q++d4bXOLSejp2uHWHsyr6PwZBaclhFhJ0U8a9yqkd55PdEiqp6bX+uFti51tdruXev8mnCYWTci02oN7hwTDCGrYwl08hExRF0SUW5kzC17cm1jjLiNhj8TpIonhb/X5FQTQrgSQvhR99/rAE4C2AfgQQCPdYc9BuBDveZyHOf28apsdiI6BOBtAL4HYHcI4Qqw+YUAYNcWn/k4EZ0gohMby68+dt1xnJtD35udiIYBfBnAJ0MIOgviFoQQHg0hHA8hHB+e6O1n7DjOraEvpxoiirG50f8shPDX3e45IpoNIVwholkAum6wQSoMkTa4vWM5EsjMLFc7OhhivsHtPSNRKHY9wz0Qlu/U+oA0W8vr2xhBLx/7g3eqvuErh1Rf6Vs8s+7M37yoxtR28wCe5Vm9xqcWuI1aeLMOctlT5N/H31rWa7xziOsKVlkt6ZwDaCcayz6/2ORaQ9soxyzLHVlllOV9tUodV0V2V2mfA0AiyyQZtneQ2WQAnVGmo8fI+KHQO+YFwcpUI87fiEtCrrn95Nv9tB81ngB8AcDJEMLnrvvRVwA81P33QwCe6DWX4zi3j37e7O8C8M8B/JSInun2/QcAnwHwF0T0MIDzAP7ZrVmi4zg3g56bPYTwbWz928F7bu5yHMe5VbgHneNkhIFGvbVDhDmRKlmmU57MG2mRhQD0o7WDasyFNS7arR/WCt30T7jXwsQLeo3NCS7kWGLL/H3cacMIxML6IS2sxfe8lbVHX+pdj7y4ZITdib6Te/eoIXfu43qpFMMA4NvXjrL2sTHtCHSwvKT6pBOPVW5po8P7lpq9yy0tNXRd9bqITpP1yAGg3eaPscwkBECpXaFlXFdLM+sjE4wU23J9KHTGJQPS3mKwEu08U43jOBLf7I6TEXyzO05GGKjNHkAq8GVVZK6xHCtqotTxyUVto9ZFmZ59b9IZXubPz7L28CVt10tnnHxTG0HxBu9rGI7Cyf6G6stXuD7ReLfOHtPe4Nejs6AdVvLTfO63T19QY2RJpKPDC2qMDCD52fJuNWa9owWJsZgfvxxpN+iWiCBaaeiAFnllG239OMr72m7pMakIPAkyOAQADGecvpBONIZNrAJfeldn3iLIRc7bx+fkqW4jF/ib3XEygm92x8kIvtkdJyP4ZnecjDBQga6ZRDhb5eWMhvJc3EkLWmG40uAOM1UjqikW+Z1zRshQY5r35Wv6WPVdvK89oudJylw5CcM6Miw2ykYNl3iGm4Ojy2pMZ4x//xYOasebe0Yu83b5ohojyy3JMkoA0Jzmt/87V46oMedWJ1Xf/pEVvsZIi3iy/rmVPaYtHGRyRiSYFN8SI+pMRasZY/TERp8lbuXlmoxBYogVrSY/llpRb8LPx/SPEZ0yQ/d2wp+/2R0nI/hmd5yM4JvdcTKCb3bHyQgDrs+eU8KNbC83tZDUSPgyrZS/xZiLZDWjlpcMRlq/Q6+xvZsLhnFFe7mVC/xYqeGdNTZUV33vnuVpqGYLK2pMJBQYWQsPAEqqwJdG1l6Xqb0A4NdHeNifrJkGAM9enVV9FwJPOTVU0B50bXFNrHRjljecJIibZqaOkimm+oles7AEOqm2WWmi+0jnLL3hghH1pjJ5m6mrxLwyJbVHvTmO45vdcTKCb3bHyQiDtdnTHBZrOmPJ9eSj3tlbSmVtI44Ih5WVuo4Wa+/iti41te1PMTeuCkXtMFOMe9vMb568qvqOlnj2mKMFHZknbXarHFY1FZlyDE+KRBiF0oa3eMeYLmNl1TpfqnJdZb2pDdC2KGwvnWMAbV6mlsOMcY8kZNnxcp5I5ns2BuWtMDNRV71lpJJOtm9vflA0jci8RDx7oWisR0XYibZHvTmO45vdcTKCb3bHyQi+2R0nIwxUoOskERaXeO2ufJxs2waASESQ7RrR6abHCtyJRdb/AoDCCBf2WkYO6FgcP+5DMNw9rNfzhuErqu8dpXOsPWI4x6yIHMOJIWzFxEWrduh9G62ot3WREqxorOfuMV3C7yedvaxdNQS6flAZlYxwMdVj6YzyFlkildD5rBrqpj+KPJ7lMNNH1Jus825lmw4ywk6KioBytKFG/+9rf7M7Tkbwze44GcE3u+NkhIHa7EiAUBNBLSLDcJLo75+ySMFsBVUsCeePhmGzjw7xFMjLRimhjigLtB60c87kWJW1K3nt5POtxWOq7zuLuka65O5R7mhzuKhLMo1EOk21pCFSmCx0RrYY+QtW5c0AMBlXVd90WfdJpB0fjMw9QegjMv00oJ2cguHUouftHUCinGy2Qtj2ORl4AiDXEnXVDZlHrskaI3UEs4Z70seYLfA3u+NkBN/sjpMRfLM7Tkbwze44GWGwAl1KiDZkBhO+BEtc6YjMMEs1o26Y8FKwssd0hPgX5rVTTeWqGGM4Pyzs5Z9bTKbUmHy1d0aT1DjXn1YO8zEjOupuaII7EN2355Iac3SIC3tWZNxKWzvaSKYK2mFob2WVr9HwYhmKuWh5dV0LhNJZyoow7OS4YNqRWWlgOKPEVvSaaBvzWH054bRCeoka4xUqs9D0ruAOOyW2dM6R527msd5yWY7j/DLim91xMkLPzU5EJSL6PhH9mIieI6I/6vYfJqLvEdEpIvoSEd2Yg7TjOAOhH5u9CeCBEMIGEcUAvk1Efwvg9wF8PoTwOBH9DwAPA/iT7SaiFMhX+feLdFLoDGl7q1Phy2zV9PdKXth77ap2qsF5bjcOr+khcZXbPFY5nXhDZGExvuZkWR5A2/9RQ1tukXDQwJKePHqW9z1d0llh/+/dPHPPmw5dVmMKOX7NxgraWUerEcBIno8bjfXn4qJ0mNEOTC2RzWbDKBElyz3litobRT4xUckYI/SS0DEceAyHGZUV1no9CjvZOFVlSsvAGAA6oMeqMy+caHJNWT9+azWg55s9bPKyShN3/wQADwD4q27/YwA+1Gsux3FuH33Z7EQUEdEzAK4BeBLAaQArIYSXXw0XAey7NUt0HOdm0NdmDyEkIYT7AOwH8E4Ab7SGWZ8loo8T0QkiOpFUe/tUO45za3hVanwIYQXAUwDuBzBORC8bPvsBaKNw8zOPhhCOhxCOR0PbZ5Z1HOfW0VOgI6IZAO0QwgoRlQG8F8BnAXwDwIcBPA7gIQBP9JwrBSJRzYhkFE9kOMNUe+uIbSHujP5cfyZe5798JCUtZuRrvaOIYlWQW4+xo5p4W5X7AdAcFfXIi3rygjiP0oKepzLHRbxTFw6pMcP3LbL2G6d0VhoZPQcAqRCBhvK6RFVRiH9HRhbVmOUWd44q5bXHylXhCJUzoiJb4hnKx4ZzjnjUEyNtdDDefUHMTUYWcRWsZ2Wh6cOLRmXPkWItoJQ+FYW3zePbjxo/C+AxIoqw+ZvAX4QQvkpEPwPwOBH9FwBPA/hCH3M5jnOb6LnZQwg/AfA2o/8MNu13x3FeB7gHneNkhMEGwgDKplCZOY1AA1neJxjO/uVL/FQmTmnjKinyeZoj+ruuuMZtueKSzkKDVNpN2kBvj2kHkU6ZG+nFRW3rTsxzT5903BA1idtpjV06m05zjB9r7EVt/60F7jJz/h8Z5akj3Rfn+PlGxv2QNnvdcLCs5PncVqaa0YrILrSug3ciEfgiA2wAoCNPw7KhLTs+FgMNR6i00Ee2GGG0W/Eq6tk3X8ViHrHkbeJg/M3uOFnBN7vjZATf7I6TEXyzO05GGKhAF3JAorUkhuWMkqvL9LlaJKlc5cpEVNdiS77GJx86r8W3XJWLZlTXIlpYXeftlp6nYIQ1FUhGXmk1Mk1ksW/L0YOPKZe0GFi85yhrbxzSQt/QJb6eC+en1ZjJUk31zZR49pqOEQomI+osx5v1Dl93td07StoS32TJrnxOj5FHtyLjEiNNtUzVnJYMBawvkUxEU1oCoaoFb81z4/ib3XEygm92x8kIvtkdJyMM1mYnICkKhxRpOlmJQUXASK5pZXgR7bq2h6XzS27FCLmNRbbbgg4EkTZ6aGnHE2lX9wsZeoQaE/ELYmkGuefOsPbYS9pmj99xB2tvHNSPw+lpnasmneRrtDLVyGCZjhH1IzPVWGW9KjG/tp2inicvymp3Ej2mUOTzWGXGUitzbR8BLDIjspXNhoxnVo0RzlpWWWnpRKMXs/WP/M3uOBnBN7vjZATf7I6TEXyzO05GGGzUG2kxI4m4CCGFNsAocWOIHVL/CXn9PZZbEoLc4opeYkWUlor1JQrSYcYQ1QhGGpogao2nVuhTH9+/ch5LDBSiYTqns9AUv8b74rf8YzWmY9Swb4o0zI2cvkYy6s0SXlOhZJXzWuicEE498tiAdqKxBLpUiF2dth4T2r2vfVo0TkTWSDdUPSm8yprugCG+WUKfuKwyHfl2Ap6/2R0nI/hmd5yM4JvdcTLCwG12mYwk1xE2fOZ/hc4AAAxfSURBVKGPUsdFbes2pvj3VhrriJspmVHmhdNqTE44qFDBqu3Uy7MByq4GtG2dK+oAFgiHmbSmA1Eozx19onFdDll+LlfRGV7mP/JW1h77p1fVmEZbPyL1Dj/+UKyDXCpCfGkbTjV54VFVzBuZdIXtXzQy0EoHHgsRgwSSdjYAMjLVqPLPhqNLEM8nyZJMgM7QZAV8CcnCOi3paGPNsxX+ZnecjOCb3XEygm92x8kIvtkdJyMMXKCDcJDReochnMgSUdLJBkBjmvc1J/XhW6PDrL1//S41JnnueX5sK6JN5iU2stJQrIW9cP+bWXvpTi2a5Zt8rnhdKzDz93GBrDNsOOeIrtasPo8jd1xi7ZnyhhozV9Pi31DMxTeZEhoAagk///W2Fkxl6mgZBQcAG20uYuYNr5GyiIyz5iGRylpmtwGAtqGIWZFwCjnGqKse1Xs7v0jxTfolAVqQU2M86s1xHN/sjpMRfLM7Tkbwze44GWGwAl2AEi+CiCKSYhyga7vJyDlAp7sqLfT+Hpv7Na3izZS4iJY7dUF/cP8h1kyLOnXV0r2jqm/+XVxNqUytqTFTwyLKy0rVJASophGZtneUz31lTa9H1myTYhgABEO0skQyyUqbi49No46bFNJyRg7mgkg5VevoMdITLzZSSZOYW7Y3O3VfaMlwSsPDU6Sglp5w1tQ5Q8TLCUdEa4lybuVB5wKd4zi+2R0nI/hmd5yMMPD67NIOUfa4keBFpdQ1IpbSIW68tIxMIOVrQi8w/CUuvneMtav/WqdgPnKMR4dNFJfUmErQmWHeJsomXaqNqzEbLW43r1bLakx9nY/JGdFaz89xB6LJvatqzIEhnqnnUm1MjYkM+1dFqxneH7IklFUiqpnwx2+iqCP8OkKzsOx6lbba0DnyomyUlbY67eg+qkubXQ1RUZmybfVJ+xww7HHrWOJ2qMu6jQ+Qv9kdJyP4ZnecjND3ZieiiIieJqKvdtuHieh7RHSKiL5E0vnYcZwdxat5s38CwMnr2p8F8PkQwjEAywAevpkLcxzn5tKXQEdE+wH8NoD/CuD3iYgAPADgo90hjwH4zwD+5FWvQAoKhviGdh9ph4RzTlLW89T28b7hc1auXtEuaIHqpWvcGWeupCPDirH2rDi7zOumNY2UT40q/wVJOXUAKsoqrGmnnuIsT5u9b1Q78Mw1+LpluikAKKhifMCYqO1WjvS51hM+Vz8OO41EH1+uyXLykaKdlW66H6xU0jKzNxnPonSQsZxqIiHIGZdV91kOMjK9VY+fs/m3/hHjjwH8IX6R/XsKwEoI4WUZ9iKAfX3O5TjObaDnZieiDwK4FkL44fXdxlDzO4WIPk5EJ4joRLJhVE11HGcg9PP7zrsA/A4RfQBACcAoNt/040SU777d9wO4bH04hPAogEcBoHjwwDa/ZDiOcyvpudlDCJ8G8GkAIKLfAPDvQggfI6K/BPBhAI8DeAjAEz2PFgzHfSM1r/U5RqS/M3IFPnFqlCRKKvxz64f1oaZ+LMpR1fV/MtRnuR1ZHddjqlaqYpliuJ/629bvXsJGjWZ0ffQ94+usbdmx0tHFcjShyEiXIrCCXGSfpQfIYBRrTFsEy8SRkWFGjGkZgUHK8cZwoLH0oiCeNavOunSQyRl2vbyvll2fk6XPjK2RilPLN8T6blEgzKewKda9iE0b/guvYS7HcW4xr0q2DCE8BeCp7r/PAHjnzV+S4zi3Avegc5yM4JvdcTLCwKPepChFIjotFAxhS3wmGNlsIhHVlI5qBSS3JBxWJvWY1WN8zMTPtVNNcZUfvzViiIFGGTcpnlhjmhMiCrBi1IwT9cdKZV3UXkZ+dVItIkpnFCuibLSgxT8Z9WZRE2KbJRDKTDWJIVgOFfg9spxqqu3entqyznxiiHiwot7E8xkZ0ZSqRroZGSc6+igXSImxF1Sdd/Fzr8/uOI5vdsfJCL7ZHScjDDy7rHSqUaWdDKMjLfVRI1v0xSXtDNKORFBFS3/XyTJJa01tD8YipqSjqzghNezx9ojQFSx9Ql4Pw9GjNMHt6H1jOguNZX9LZKYYi5IR5GIFvkg6IuVQ3sh4s1rXJaEkwkRFwajPLp2BWkaAkazQlVrOXH2UZFK2N/p0mBGf60P2QBobz7l4ZGW5MM8u6ziOb3bHyQq+2R0nI/hmd5yMMFCBjoIWKpSvh1UPW3YZQ5JEfG8ZAois667SBAMIFf7Bxh49UVLkxzKyJJviWyIdZIzoPRllVRjWDjMjFS7Q1QynktGidoaR9FPGKTVOTtZVb8tQLGinnlpbR7Q1G7zPdA4S9zUf6Ztfb/F5LPFNPh9p3Xj0rSw4DenEYjjV9OPYIjPMGA4zwTg3iRYDBxP15jjO6wjf7I6TEXyzO05GGLhTjbR5SDifWKVzrOAYSdrkdiMZ9jBEBlpLH6Ait9GDUVqpLWxWs8y0lSVXYozJl7moMVzRtrcsyWSVaJLOMB3Drk6Fx4qVKcYiJwzQ1bZ2jllr8r5qQ+sKJM7fCnJpC9s/To1MNSKoJZX6DYBEPB9WxuKc4WQl7XGZJRbYPvjklTE3KSGbdErL14XNnm59IH+zO05G8M3uOBnBN7vjZATf7I6TEQbvVCMigmT0j6V16Mg4Q4QQaZqDUbaJhFNNkIIdgNHROmvXajp8TepxqSHsmCmyRYaZuGJElAnHknKsw6wmy7yO+aGhRX144QxjZZdZF8JaangrWY43V0XZqIX6sBpTFdGCMlOMRbutx8QxX7dVMqvTlgKdce1FaSdLVJUZZwAgJ1JHWxFt6qHtIzv6dtFprwwxLpkU6OIqfz48U43jOL7ZHScr+GZ3nIwwWKeaFMhzcxNJSdhEeSOIQQaQGF9R0YYIdDAcNKjI7eFg+JBUijoYQ1Inbo9GQ0YGWMMmG6lwj4yZoQ01RjrD7K+sqDG7Cry0k3RyAYBIGG+NtLfDzFJLp9xZbmp7fLXFbf1moo3LepMfr1XTx4+ErhIMezMnHG+sBC/thniMDQ2FROZYK6BFlV+C1pQsm1hJSNZ5dHrVWtZxONYti0S5p6gqRAR3qnEcxze742QE3+yOkxF8sztORqBgKUm36mBE8wBeAjANYGFgB745vB7XDLw+1+1rvnHuCCHMWD8Y6GZ/5aBEJ0IIxwd+4NfA63HNwOtz3b7mW4P/Gu84GcE3u+NkhNu12R+9Tcd9Lbwe1wy8Ptfta74F3Bab3XGcweO/xjtORhj4Ziei9xPR80T0IhE9Mujj9wMRfZGIrhHRs9f1TRLRk0R0qvv3xO1co4SIDhDRN4joJBE9R0Sf6Pbv2HUTUYmIvk9EP+6u+Y+6/YeJ6HvdNX+JiHS2ytsMEUVE9DQRfbXb3vFrHuhmJ6IIwH8H8FsA3gTgI0T0pkGuoU/+FMD7Rd8jAL4eQjgG4Ovd9k6iA+APQghvBHA/gH/TvbY7ed1NAA+EEN4K4D4A7yei+wF8FsDnu2teBvDwbVzjVnwCwMnr2jt+zYN+s78TwIshhDMhhBaAxwE8OOA19CSE8E0AS6L7QQCPdf/9GIAPDXRRPQghXAkh/Kj773VsPoj7sIPXHTZ5OfQv7v4JAB4A8Ffd/h21ZgAgov0AfhvA/+y2CTt8zcDgN/s+ABeua1/s9r0e2B1CuAJsbiwAu27zeraEiA4BeBuA72GHr7v76/AzAK4BeBLAaQArIYSX8y3txGfkjwH8IX4RzDqFnb/mgW92KzuX/3fATYSIhgF8GcAnQwhrt3s9vQghJCGE+wDsx+Zvfm+0hg12VVtDRB8EcC2E8MPru42hO2bNLzPY5BWb33gHrmvvB3B5wGu4UeaIaDaEcIWIZrH5JtpREFGMzY3+ZyGEv+527/h1A0AIYYWInsKm3jBORPnum3KnPSPvAvA7RPQBACUAo9h80+/kNQMY/Jv9BwCOdZXLAoDfA/CVAa/hRvkKgIe6/34IwBO3cS2Krt34BQAnQwifu+5HO3bdRDRDROPdf5cBvBebWsM3AHy4O2xHrTmE8OkQwv4QwiFsPr9/H0L4GHbwml8hhDDQPwA+AOAFbNpm/3HQx+9zjX8O4AqANjZ/G3kYm3bZ1wGc6v49ebvXKdb8a9j81fEnAJ7p/vnATl43gHsBPN1d87MA/lO3/wiA7wN4EcBfAije7rVusf7fAPDV18ua3YPOcTKCe9A5Tkbwze44GcE3u+NkBN/sjpMRfLM7Tkbwze44GcE3u+NkBN/sjpMR/j8EIXCea2IlBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This looks reasonable!\n",
    "plt.figure()\n",
    "plt.imshow(X_train[1005].reshape(48, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Use [VGG16](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16) as a starting point, then add additional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0901 18:19:10.920516 4385318336 deprecation.py:506] From /Users/camesmith/miniconda/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Reshape\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16 = VGG16(include_top=False, input_shape=(48, 48, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current shape: (28709,). Required shape: (48, 48, 3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a format that VGG16 will accept\n",
    "def convert_format(X_data):\n",
    "    # Normalize data to [0, 1] range\n",
    "    X_data = X_data / 255\n",
    "    \n",
    "    # Reshape to (n, 48, 48, 1)\n",
    "    x = np.array([i.reshape(48, 48, 1) for i in X_data])\n",
    "    \n",
    "    # Collect into one large list.\n",
    "    x = x.reshape(len(x) * 48 * 48 * 1)\n",
    "    \n",
    "    # Duplicate (three times) each item in the list\n",
    "    x = [i for i in x for _ in range(0, 3)]\n",
    "    \n",
    "    # Reshape into (n, 48, 48, 3)\n",
    "    x = np.array(x).reshape(len(X_data), 48, 48, 3)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = convert_format(X_train)\n",
    "X_val = convert_format(X_val)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "vgg16.compile(optimizer=\"adam\", loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 1, 1, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our data through the model to get its \"prediction.\" This might take a little while.\n",
    "vgg16_output_train = vgg16.predict(X_train)\n",
    "vgg16_output_val = vgg16.predict(X_val)\n",
    "\n",
    "# Expected (n, 1, 1, 512) shape.\n",
    "vgg16_output_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we generate our own model that takes the output of vgg16 and fits it to our data.\n",
    "topLayerModel = Sequential()\n",
    "topLayerModel.add(Reshape((512,), input_shape=(1, 1, 512)))\n",
    "topLayerModel.add(Dense(256, input_shape=(512,), activation='relu')) # should have same shape as vgg16 output\n",
    "topLayerModel.add(Dense(256, input_shape=(256,), activation='relu'))\n",
    "topLayerModel.add(Dropout(0.5))\n",
    "topLayerModel.add(Dense(128, input_shape=(256,), activation='relu'))\n",
    "topLayerModel.add(Dense(7, activation='softmax')) # 7 categories in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 7), (3589, 7))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the category output to a 1-hot encoded vector.\n",
    "y_train_onehot = to_categorical(y_train)\n",
    "y_val_onehot = to_categorical(y_val)\n",
    "y_train_onehot.shape, y_val_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "topLayerModel.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/500\n",
      "28709/28709 [==============================] - 5s 162us/sample - loss: 1.6565 - acc: 0.3450 - val_loss: 1.5776 - val_acc: 0.3884\n",
      "Epoch 2/500\n",
      "28709/28709 [==============================] - 4s 138us/sample - loss: 1.5694 - acc: 0.3913 - val_loss: 1.5375 - val_acc: 0.4015\n",
      "Epoch 3/500\n",
      "28709/28709 [==============================] - 4s 139us/sample - loss: 1.5276 - acc: 0.4094 - val_loss: 1.5086 - val_acc: 0.4085\n",
      "Epoch 4/500\n",
      "28709/28709 [==============================] - 4s 140us/sample - loss: 1.4897 - acc: 0.4243 - val_loss: 1.4965 - val_acc: 0.4163\n",
      "Epoch 5/500\n",
      "28709/28709 [==============================] - 4s 141us/sample - loss: 1.4592 - acc: 0.4374 - val_loss: 1.4720 - val_acc: 0.4277\n",
      "Epoch 6/500\n",
      "28709/28709 [==============================] - 4s 142us/sample - loss: 1.4276 - acc: 0.4546 - val_loss: 1.4843 - val_acc: 0.4257\n",
      "Epoch 7/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 1.3965 - acc: 0.4660 - val_loss: 1.4633 - val_acc: 0.4341\n",
      "Epoch 8/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 1.3617 - acc: 0.4804 - val_loss: 1.4799 - val_acc: 0.4408\n",
      "Epoch 9/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 1.3329 - acc: 0.4910 - val_loss: 1.4537 - val_acc: 0.4408\n",
      "Epoch 10/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 1.3005 - acc: 0.5052 - val_loss: 1.4665 - val_acc: 0.4374\n",
      "Epoch 11/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 1.2730 - acc: 0.5164 - val_loss: 1.4677 - val_acc: 0.4455\n",
      "Epoch 12/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 1.2356 - acc: 0.5317 - val_loss: 1.4781 - val_acc: 0.4444\n",
      "Epoch 13/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 1.2107 - acc: 0.5437 - val_loss: 1.5361 - val_acc: 0.4232\n",
      "Epoch 14/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 1.1787 - acc: 0.5560 - val_loss: 1.5180 - val_acc: 0.4425\n",
      "Epoch 15/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 1.1568 - acc: 0.5647 - val_loss: 1.5348 - val_acc: 0.4408\n",
      "Epoch 16/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 1.1256 - acc: 0.5772 - val_loss: 1.5652 - val_acc: 0.4514\n",
      "Epoch 17/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 1.0990 - acc: 0.5878 - val_loss: 1.5670 - val_acc: 0.4452\n",
      "Epoch 18/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 1.0705 - acc: 0.5959 - val_loss: 1.5664 - val_acc: 0.4480\n",
      "Epoch 19/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 1.0543 - acc: 0.6017 - val_loss: 1.6092 - val_acc: 0.4450\n",
      "Epoch 20/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 1.0313 - acc: 0.6113 - val_loss: 1.6127 - val_acc: 0.4466\n",
      "Epoch 21/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 1.0066 - acc: 0.6189 - val_loss: 1.6428 - val_acc: 0.4374\n",
      "Epoch 22/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.9876 - acc: 0.6336 - val_loss: 1.6504 - val_acc: 0.4416\n",
      "Epoch 23/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.9602 - acc: 0.6382 - val_loss: 1.7350 - val_acc: 0.4386\n",
      "Epoch 24/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.9468 - acc: 0.6421 - val_loss: 1.7179 - val_acc: 0.4405\n",
      "Epoch 25/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.9237 - acc: 0.6526 - val_loss: 1.7861 - val_acc: 0.4310\n",
      "Epoch 26/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.9112 - acc: 0.6574 - val_loss: 1.7391 - val_acc: 0.4475\n",
      "Epoch 27/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.8972 - acc: 0.6641 - val_loss: 1.7692 - val_acc: 0.4447\n",
      "Epoch 28/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.8788 - acc: 0.6703 - val_loss: 1.7967 - val_acc: 0.4586\n",
      "Epoch 29/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.8639 - acc: 0.6773 - val_loss: 1.9077 - val_acc: 0.4581\n",
      "Epoch 30/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.8509 - acc: 0.6832 - val_loss: 1.8893 - val_acc: 0.4639\n",
      "Epoch 31/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.8425 - acc: 0.6859 - val_loss: 1.9038 - val_acc: 0.4611\n",
      "Epoch 32/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.8190 - acc: 0.6958 - val_loss: 1.9096 - val_acc: 0.4461\n",
      "Epoch 33/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.8186 - acc: 0.6933 - val_loss: 1.9417 - val_acc: 0.4650\n",
      "Epoch 34/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.8016 - acc: 0.6992 - val_loss: 1.8851 - val_acc: 0.4597\n",
      "Epoch 35/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.7848 - acc: 0.7080 - val_loss: 2.0371 - val_acc: 0.4617\n",
      "Epoch 36/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.7810 - acc: 0.7066 - val_loss: 1.9424 - val_acc: 0.4586\n",
      "Epoch 37/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.7620 - acc: 0.7163 - val_loss: 2.0745 - val_acc: 0.4592\n",
      "Epoch 38/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.7509 - acc: 0.7195 - val_loss: 2.0285 - val_acc: 0.4600\n",
      "Epoch 39/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.7417 - acc: 0.7226 - val_loss: 2.0872 - val_acc: 0.4511\n",
      "Epoch 40/500\n",
      "28709/28709 [==============================] - 4s 155us/sample - loss: 0.7302 - acc: 0.7271 - val_loss: 2.1105 - val_acc: 0.4578\n",
      "Epoch 41/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.7159 - acc: 0.7336 - val_loss: 2.1680 - val_acc: 0.4586\n",
      "Epoch 42/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.7106 - acc: 0.7334 - val_loss: 2.1937 - val_acc: 0.4611\n",
      "Epoch 43/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.7024 - acc: 0.7403 - val_loss: 2.1612 - val_acc: 0.4575\n",
      "Epoch 44/500\n",
      "28709/28709 [==============================] - 5s 159us/sample - loss: 0.6947 - acc: 0.7431 - val_loss: 2.2693 - val_acc: 0.4472\n",
      "Epoch 45/500\n",
      "28709/28709 [==============================] - 5s 159us/sample - loss: 0.6859 - acc: 0.7451 - val_loss: 2.2829 - val_acc: 0.4597\n",
      "Epoch 46/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.6796 - acc: 0.7486 - val_loss: 2.3163 - val_acc: 0.4525\n",
      "Epoch 47/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.6695 - acc: 0.7503 - val_loss: 2.2575 - val_acc: 0.4620\n",
      "Epoch 48/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.6632 - acc: 0.7511 - val_loss: 2.4085 - val_acc: 0.4645\n",
      "Epoch 49/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.6550 - acc: 0.7590 - val_loss: 2.3552 - val_acc: 0.4575\n",
      "Epoch 50/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.6412 - acc: 0.7600 - val_loss: 2.3979 - val_acc: 0.4645\n",
      "Epoch 51/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.6419 - acc: 0.7612 - val_loss: 2.2848 - val_acc: 0.4600\n",
      "Epoch 52/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.6276 - acc: 0.7680 - val_loss: 2.4270 - val_acc: 0.4581\n",
      "Epoch 53/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.6258 - acc: 0.7671 - val_loss: 2.4962 - val_acc: 0.4539\n",
      "Epoch 54/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.6186 - acc: 0.7700 - val_loss: 2.3788 - val_acc: 0.4544\n",
      "Epoch 55/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.6075 - acc: 0.7743 - val_loss: 2.4246 - val_acc: 0.4578\n",
      "Epoch 56/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.6003 - acc: 0.7744 - val_loss: 2.5594 - val_acc: 0.4508\n",
      "Epoch 57/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.5929 - acc: 0.7780 - val_loss: 2.5954 - val_acc: 0.4531\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.5924 - acc: 0.7796 - val_loss: 2.5851 - val_acc: 0.4450\n",
      "Epoch 59/500\n",
      "28709/28709 [==============================] - 4s 157us/sample - loss: 0.5792 - acc: 0.7839 - val_loss: 2.6493 - val_acc: 0.4634\n",
      "Epoch 60/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.5800 - acc: 0.7871 - val_loss: 2.6347 - val_acc: 0.4544\n",
      "Epoch 61/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.5737 - acc: 0.7883 - val_loss: 2.7026 - val_acc: 0.4503\n",
      "Epoch 62/500\n",
      "28709/28709 [==============================] - 5s 163us/sample - loss: 0.5698 - acc: 0.7892 - val_loss: 2.5650 - val_acc: 0.4503\n",
      "Epoch 63/500\n",
      "28709/28709 [==============================] - 5s 166us/sample - loss: 0.5614 - acc: 0.7929 - val_loss: 2.7134 - val_acc: 0.4558\n",
      "Epoch 64/500\n",
      "28709/28709 [==============================] - 5s 164us/sample - loss: 0.5579 - acc: 0.7933 - val_loss: 2.6710 - val_acc: 0.4589\n",
      "Epoch 65/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.5488 - acc: 0.7957 - val_loss: 2.7764 - val_acc: 0.4539\n",
      "Epoch 66/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.5476 - acc: 0.7991 - val_loss: 2.8074 - val_acc: 0.4570\n",
      "Epoch 67/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.5381 - acc: 0.7983 - val_loss: 2.7844 - val_acc: 0.4528\n",
      "Epoch 68/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.5301 - acc: 0.8033 - val_loss: 2.8316 - val_acc: 0.4511\n",
      "Epoch 69/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.5343 - acc: 0.7991 - val_loss: 2.8343 - val_acc: 0.4505\n",
      "Epoch 70/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.5266 - acc: 0.8054 - val_loss: 2.9399 - val_acc: 0.4597\n",
      "Epoch 71/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.5117 - acc: 0.8100 - val_loss: 2.8973 - val_acc: 0.4592\n",
      "Epoch 72/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.5227 - acc: 0.8084 - val_loss: 2.8192 - val_acc: 0.4536\n",
      "Epoch 73/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.5240 - acc: 0.8054 - val_loss: 2.8957 - val_acc: 0.4480\n",
      "Epoch 74/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.5017 - acc: 0.8136 - val_loss: 2.9650 - val_acc: 0.4489\n",
      "Epoch 75/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.5071 - acc: 0.8098 - val_loss: 2.9531 - val_acc: 0.4508\n",
      "Epoch 76/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4904 - acc: 0.8160 - val_loss: 2.9495 - val_acc: 0.4528\n",
      "Epoch 77/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.5040 - acc: 0.8110 - val_loss: 3.0085 - val_acc: 0.4572\n",
      "Epoch 78/500\n",
      "28709/28709 [==============================] - 5s 159us/sample - loss: 0.4914 - acc: 0.8156 - val_loss: 3.0857 - val_acc: 0.4503\n",
      "Epoch 79/500\n",
      "28709/28709 [==============================] - 5s 160us/sample - loss: 0.4865 - acc: 0.8197 - val_loss: 3.1880 - val_acc: 0.4436\n",
      "Epoch 80/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.4834 - acc: 0.8184 - val_loss: 3.0498 - val_acc: 0.4567\n",
      "Epoch 81/500\n",
      "28709/28709 [==============================] - 4s 155us/sample - loss: 0.4777 - acc: 0.8238 - val_loss: 3.0904 - val_acc: 0.4494\n",
      "Epoch 82/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4829 - acc: 0.8203 - val_loss: 3.0963 - val_acc: 0.4505\n",
      "Epoch 83/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.4699 - acc: 0.8254 - val_loss: 3.1535 - val_acc: 0.4525\n",
      "Epoch 84/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.4715 - acc: 0.8233 - val_loss: 3.2355 - val_acc: 0.4639\n",
      "Epoch 85/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4669 - acc: 0.8265 - val_loss: 3.2064 - val_acc: 0.4483\n",
      "Epoch 86/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.4583 - acc: 0.8285 - val_loss: 3.2522 - val_acc: 0.4533\n",
      "Epoch 87/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.4684 - acc: 0.8251 - val_loss: 3.2826 - val_acc: 0.4622\n",
      "Epoch 88/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.4625 - acc: 0.8298 - val_loss: 3.1927 - val_acc: 0.4531\n",
      "Epoch 89/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.4567 - acc: 0.8313 - val_loss: 3.1323 - val_acc: 0.4511\n",
      "Epoch 90/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4479 - acc: 0.8360 - val_loss: 3.3314 - val_acc: 0.4439\n",
      "Epoch 91/500\n",
      "28709/28709 [==============================] - 5s 159us/sample - loss: 0.4542 - acc: 0.8338 - val_loss: 3.2660 - val_acc: 0.4455\n",
      "Epoch 92/500\n",
      "28709/28709 [==============================] - 5s 163us/sample - loss: 0.4440 - acc: 0.8347 - val_loss: 3.2417 - val_acc: 0.4583\n",
      "Epoch 93/500\n",
      "28709/28709 [==============================] - 5s 164us/sample - loss: 0.4356 - acc: 0.8395 - val_loss: 3.3700 - val_acc: 0.4542\n",
      "Epoch 94/500\n",
      "28709/28709 [==============================] - 5s 161us/sample - loss: 0.4452 - acc: 0.8356 - val_loss: 3.2155 - val_acc: 0.4478\n",
      "Epoch 95/500\n",
      "28709/28709 [==============================] - 5s 159us/sample - loss: 0.4413 - acc: 0.8373 - val_loss: 3.2995 - val_acc: 0.4586\n",
      "Epoch 96/500\n",
      "28709/28709 [==============================] - 5s 159us/sample - loss: 0.4324 - acc: 0.8377 - val_loss: 3.4059 - val_acc: 0.4478\n",
      "Epoch 97/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.4291 - acc: 0.8425 - val_loss: 3.3187 - val_acc: 0.4631\n",
      "Epoch 98/500\n",
      "28709/28709 [==============================] - 4s 155us/sample - loss: 0.4219 - acc: 0.8413 - val_loss: 3.3998 - val_acc: 0.4511\n",
      "Epoch 99/500\n",
      "28709/28709 [==============================] - 4s 155us/sample - loss: 0.4218 - acc: 0.8470 - val_loss: 3.3654 - val_acc: 0.4622\n",
      "Epoch 100/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4246 - acc: 0.8443 - val_loss: 3.5064 - val_acc: 0.4355\n",
      "Epoch 101/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4243 - acc: 0.8422 - val_loss: 3.4554 - val_acc: 0.4581\n",
      "Epoch 102/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4198 - acc: 0.8444 - val_loss: 3.3788 - val_acc: 0.4556\n",
      "Epoch 103/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.4073 - acc: 0.8477 - val_loss: 3.4946 - val_acc: 0.4514\n",
      "Epoch 104/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3977 - acc: 0.8520 - val_loss: 3.6080 - val_acc: 0.4556\n",
      "Epoch 105/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.4107 - acc: 0.8488 - val_loss: 3.4749 - val_acc: 0.4558\n",
      "Epoch 106/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.4011 - acc: 0.8505 - val_loss: 3.5659 - val_acc: 0.4561\n",
      "Epoch 107/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.3995 - acc: 0.8504 - val_loss: 3.6386 - val_acc: 0.4483\n",
      "Epoch 108/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.3951 - acc: 0.8531 - val_loss: 3.6651 - val_acc: 0.4586\n",
      "Epoch 109/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.4005 - acc: 0.8533 - val_loss: 3.4886 - val_acc: 0.4522\n",
      "Epoch 110/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.4017 - acc: 0.8494 - val_loss: 3.5799 - val_acc: 0.4603\n",
      "Epoch 111/500\n",
      "28709/28709 [==============================] - 4s 146us/sample - loss: 0.3846 - acc: 0.8601 - val_loss: 3.6693 - val_acc: 0.4558\n",
      "Epoch 112/500\n",
      "28709/28709 [==============================] - 4s 144us/sample - loss: 0.3911 - acc: 0.8536 - val_loss: 3.5722 - val_acc: 0.4447\n",
      "Epoch 113/500\n",
      "28709/28709 [==============================] - 4s 144us/sample - loss: 0.3870 - acc: 0.8558 - val_loss: 3.6439 - val_acc: 0.4514\n",
      "Epoch 114/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3799 - acc: 0.8590 - val_loss: 3.6401 - val_acc: 0.4564\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.3822 - acc: 0.8591 - val_loss: 3.6269 - val_acc: 0.4531\n",
      "Epoch 116/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3791 - acc: 0.8582 - val_loss: 3.6445 - val_acc: 0.4544\n",
      "Epoch 117/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.3854 - acc: 0.8577 - val_loss: 3.7765 - val_acc: 0.4536\n",
      "Epoch 118/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.3733 - acc: 0.8617 - val_loss: 3.7558 - val_acc: 0.4539\n",
      "Epoch 119/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.3736 - acc: 0.8627 - val_loss: 3.8565 - val_acc: 0.4558\n",
      "Epoch 120/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.3662 - acc: 0.8640 - val_loss: 3.8858 - val_acc: 0.4564\n",
      "Epoch 121/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3815 - acc: 0.8599 - val_loss: 3.7009 - val_acc: 0.4614\n",
      "Epoch 122/500\n",
      "28709/28709 [==============================] - 4s 155us/sample - loss: 0.3687 - acc: 0.8650 - val_loss: 3.8971 - val_acc: 0.4480\n",
      "Epoch 123/500\n",
      "28709/28709 [==============================] - 4s 157us/sample - loss: 0.3616 - acc: 0.8682 - val_loss: 3.7482 - val_acc: 0.4581\n",
      "Epoch 124/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.3643 - acc: 0.8637 - val_loss: 3.8274 - val_acc: 0.4597\n",
      "Epoch 125/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.3553 - acc: 0.8698 - val_loss: 3.9506 - val_acc: 0.4511\n",
      "Epoch 126/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3530 - acc: 0.8691 - val_loss: 3.9310 - val_acc: 0.4553\n",
      "Epoch 127/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.3616 - acc: 0.8677 - val_loss: 3.8760 - val_acc: 0.4478\n",
      "Epoch 128/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3499 - acc: 0.8705 - val_loss: 3.9238 - val_acc: 0.4483\n",
      "Epoch 129/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3484 - acc: 0.8698 - val_loss: 3.9798 - val_acc: 0.4419\n",
      "Epoch 130/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.3473 - acc: 0.8719 - val_loss: 3.8489 - val_acc: 0.4525\n",
      "Epoch 131/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.3432 - acc: 0.8725 - val_loss: 4.0041 - val_acc: 0.4519\n",
      "Epoch 132/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.3504 - acc: 0.8709 - val_loss: 3.8340 - val_acc: 0.4572\n",
      "Epoch 133/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3509 - acc: 0.8696 - val_loss: 3.9947 - val_acc: 0.4581\n",
      "Epoch 134/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3434 - acc: 0.8769 - val_loss: 3.9301 - val_acc: 0.4542\n",
      "Epoch 135/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3354 - acc: 0.8753 - val_loss: 3.9774 - val_acc: 0.4550\n",
      "Epoch 136/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3498 - acc: 0.8690 - val_loss: 3.9816 - val_acc: 0.4447\n",
      "Epoch 137/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.3335 - acc: 0.8774 - val_loss: 4.0333 - val_acc: 0.4508\n",
      "Epoch 138/500\n",
      "28709/28709 [==============================] - 4s 157us/sample - loss: 0.3439 - acc: 0.8750 - val_loss: 3.9663 - val_acc: 0.4475\n",
      "Epoch 139/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.3317 - acc: 0.8776 - val_loss: 4.0740 - val_acc: 0.4511\n",
      "Epoch 140/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.3421 - acc: 0.8754 - val_loss: 4.0223 - val_acc: 0.4595\n",
      "Epoch 141/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.3337 - acc: 0.8783 - val_loss: 4.0166 - val_acc: 0.4603\n",
      "Epoch 142/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3349 - acc: 0.8781 - val_loss: 3.9298 - val_acc: 0.4466\n",
      "Epoch 143/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3288 - acc: 0.8802 - val_loss: 4.0378 - val_acc: 0.4494\n",
      "Epoch 144/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3244 - acc: 0.8811 - val_loss: 3.9561 - val_acc: 0.4492\n",
      "Epoch 145/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3288 - acc: 0.8810 - val_loss: 4.0349 - val_acc: 0.4517\n",
      "Epoch 146/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3173 - acc: 0.8810 - val_loss: 4.3277 - val_acc: 0.4514\n",
      "Epoch 147/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.3279 - acc: 0.8785 - val_loss: 4.0211 - val_acc: 0.4536\n",
      "Epoch 148/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.3229 - acc: 0.8808 - val_loss: 4.1520 - val_acc: 0.4505\n",
      "Epoch 149/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.3151 - acc: 0.8837 - val_loss: 4.2746 - val_acc: 0.4452\n",
      "Epoch 150/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.3217 - acc: 0.8812 - val_loss: 4.3037 - val_acc: 0.4464\n",
      "Epoch 151/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3139 - acc: 0.8853 - val_loss: 4.1305 - val_acc: 0.4558\n",
      "Epoch 152/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.3151 - acc: 0.8855 - val_loss: 4.2079 - val_acc: 0.4556\n",
      "Epoch 153/500\n",
      "28709/28709 [==============================] - 4s 157us/sample - loss: 0.3096 - acc: 0.8845 - val_loss: 4.2359 - val_acc: 0.4536\n",
      "Epoch 154/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.3137 - acc: 0.8850 - val_loss: 4.4996 - val_acc: 0.4461\n",
      "Epoch 155/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.3163 - acc: 0.8864 - val_loss: 4.5117 - val_acc: 0.4556\n",
      "Epoch 156/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.3138 - acc: 0.8855 - val_loss: 4.3321 - val_acc: 0.4472\n",
      "Epoch 157/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.3102 - acc: 0.8857 - val_loss: 4.2757 - val_acc: 0.4519\n",
      "Epoch 158/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.3053 - acc: 0.8902 - val_loss: 4.6090 - val_acc: 0.4592\n",
      "Epoch 159/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3052 - acc: 0.8848 - val_loss: 4.2696 - val_acc: 0.4466\n",
      "Epoch 160/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3057 - acc: 0.8884 - val_loss: 4.2862 - val_acc: 0.4547\n",
      "Epoch 161/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3078 - acc: 0.8906 - val_loss: 4.3375 - val_acc: 0.4511\n",
      "Epoch 162/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2910 - acc: 0.8929 - val_loss: 4.1987 - val_acc: 0.4514\n",
      "Epoch 163/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.3066 - acc: 0.8901 - val_loss: 4.3240 - val_acc: 0.4620\n",
      "Epoch 164/500\n",
      "28709/28709 [==============================] - 4s 151us/sample - loss: 0.3026 - acc: 0.8893 - val_loss: 4.3190 - val_acc: 0.4492\n",
      "Epoch 165/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.2983 - acc: 0.8920 - val_loss: 4.2602 - val_acc: 0.4466\n",
      "Epoch 166/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.2976 - acc: 0.8924 - val_loss: 4.3098 - val_acc: 0.4466\n",
      "Epoch 167/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.2898 - acc: 0.8939 - val_loss: 4.3328 - val_acc: 0.4519\n",
      "Epoch 168/500\n",
      "28709/28709 [==============================] - 4s 153us/sample - loss: 0.2979 - acc: 0.8906 - val_loss: 4.3732 - val_acc: 0.4475\n",
      "Epoch 169/500\n",
      "28709/28709 [==============================] - 4s 155us/sample - loss: 0.2875 - acc: 0.8954 - val_loss: 4.5796 - val_acc: 0.4586\n",
      "Epoch 170/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.2935 - acc: 0.8946 - val_loss: 4.4567 - val_acc: 0.4536\n",
      "Epoch 171/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.2917 - acc: 0.8921 - val_loss: 4.5089 - val_acc: 0.4427\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.2854 - acc: 0.8973 - val_loss: 4.4924 - val_acc: 0.4597\n",
      "Epoch 173/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2828 - acc: 0.8977 - val_loss: 4.6782 - val_acc: 0.4436\n",
      "Epoch 174/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2909 - acc: 0.8937 - val_loss: 4.4145 - val_acc: 0.4497\n",
      "Epoch 175/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2779 - acc: 0.8989 - val_loss: 4.6202 - val_acc: 0.4570\n",
      "Epoch 176/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2817 - acc: 0.8973 - val_loss: 4.7879 - val_acc: 0.4483\n",
      "Epoch 177/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2847 - acc: 0.8962 - val_loss: 4.5953 - val_acc: 0.4553\n",
      "Epoch 178/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2777 - acc: 0.8977 - val_loss: 4.6290 - val_acc: 0.4547\n",
      "Epoch 179/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2842 - acc: 0.8971 - val_loss: 4.5780 - val_acc: 0.4478\n",
      "Epoch 180/500\n",
      "28709/28709 [==============================] - 4s 143us/sample - loss: 0.2727 - acc: 0.8994 - val_loss: 4.6556 - val_acc: 0.4539\n",
      "Epoch 181/500\n",
      "28709/28709 [==============================] - 4s 144us/sample - loss: 0.2763 - acc: 0.8990 - val_loss: 4.8772 - val_acc: 0.4480\n",
      "Epoch 182/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2783 - acc: 0.8968 - val_loss: 4.4801 - val_acc: 0.4505\n",
      "Epoch 183/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.2697 - acc: 0.9031 - val_loss: 4.5870 - val_acc: 0.4536\n",
      "Epoch 184/500\n",
      "28709/28709 [==============================] - 4s 156us/sample - loss: 0.2842 - acc: 0.8962 - val_loss: 4.4097 - val_acc: 0.4503\n",
      "Epoch 185/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.2710 - acc: 0.9021 - val_loss: 4.6489 - val_acc: 0.4458\n",
      "Epoch 186/500\n",
      "28709/28709 [==============================] - 5s 157us/sample - loss: 0.2634 - acc: 0.9039 - val_loss: 4.5415 - val_acc: 0.4539\n",
      "Epoch 187/500\n",
      "28709/28709 [==============================] - 4s 154us/sample - loss: 0.2747 - acc: 0.9006 - val_loss: 4.7385 - val_acc: 0.4514\n",
      "Epoch 188/500\n",
      "28709/28709 [==============================] - 4s 149us/sample - loss: 0.2626 - acc: 0.9025 - val_loss: 4.7429 - val_acc: 0.4469\n",
      "Epoch 189/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2725 - acc: 0.9007 - val_loss: 4.5402 - val_acc: 0.4514\n",
      "Epoch 190/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2644 - acc: 0.9038 - val_loss: 4.7065 - val_acc: 0.4441\n",
      "Epoch 191/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2645 - acc: 0.9042 - val_loss: 4.7241 - val_acc: 0.4503\n",
      "Epoch 192/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2672 - acc: 0.9056 - val_loss: 4.6384 - val_acc: 0.4533\n",
      "Epoch 193/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2655 - acc: 0.9017 - val_loss: 4.5940 - val_acc: 0.4439\n",
      "Epoch 194/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2580 - acc: 0.9044 - val_loss: 4.7282 - val_acc: 0.4539\n",
      "Epoch 195/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2646 - acc: 0.9033 - val_loss: 4.8079 - val_acc: 0.4519\n",
      "Epoch 196/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2571 - acc: 0.9073 - val_loss: 4.7272 - val_acc: 0.4589\n",
      "Epoch 197/500\n",
      "28709/28709 [==============================] - 4s 147us/sample - loss: 0.2482 - acc: 0.9090 - val_loss: 4.8440 - val_acc: 0.4508\n",
      "Epoch 198/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2549 - acc: 0.9079 - val_loss: 4.6789 - val_acc: 0.4536\n",
      "Epoch 199/500\n",
      "28709/28709 [==============================] - 4s 155us/sample - loss: 0.2623 - acc: 0.9057 - val_loss: 4.8698 - val_acc: 0.4458\n",
      "Epoch 200/500\n",
      "28709/28709 [==============================] - 5s 159us/sample - loss: 0.2531 - acc: 0.9075 - val_loss: 4.9395 - val_acc: 0.4461\n",
      "Epoch 201/500\n",
      "28709/28709 [==============================] - 5s 165us/sample - loss: 0.2540 - acc: 0.9072 - val_loss: 4.7979 - val_acc: 0.4511\n",
      "Epoch 202/500\n",
      "28709/28709 [==============================] - 5s 165us/sample - loss: 0.2541 - acc: 0.9087 - val_loss: 4.7549 - val_acc: 0.4447\n",
      "Epoch 203/500\n",
      "28709/28709 [==============================] - 5s 160us/sample - loss: 0.2584 - acc: 0.9044 - val_loss: 4.8466 - val_acc: 0.4469\n",
      "Epoch 204/500\n",
      "28709/28709 [==============================] - 5s 158us/sample - loss: 0.2538 - acc: 0.9072 - val_loss: 4.7383 - val_acc: 0.4489\n",
      "Epoch 205/500\n",
      "28709/28709 [==============================] - 4s 152us/sample - loss: 0.2506 - acc: 0.9073 - val_loss: 4.9522 - val_acc: 0.4609\n",
      "Epoch 206/500\n",
      "28709/28709 [==============================] - 4s 150us/sample - loss: 0.2467 - acc: 0.9099 - val_loss: 5.0209 - val_acc: 0.4489\n",
      "Epoch 207/500\n",
      "28709/28709 [==============================] - 4s 148us/sample - loss: 0.2517 - acc: 0.9104 - val_loss: 4.8670 - val_acc: 0.4427\n",
      "Epoch 208/500\n",
      "24320/28709 [========================>.....] - ETA: 0s - loss: 0.2488 - acc: 0.9101"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c22fb6c0ff95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m topLayerModel.fit(vgg16_output_train, y_train_onehot,\n\u001b[1;32m      3\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_output_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           epochs=500)\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model. Accuracy on the validation set tops off early, at ~0.45.\n",
    "topLayerModel.fit(vgg16_output_train, y_train_onehot,\n",
    "          validation_data=(vgg16_output_val, y_val_onehot),\n",
    "          epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Combined Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape and both models that will be used.\n",
    "inputs = Input(shape=(48, 48, 3))\n",
    "vgg_output = vgg16(inputs)\n",
    "model_predictions = topLayerModel(vgg_output)\n",
    "final_model = Model(inputs, model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "final_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model\n",
    "### not working ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 19:10:10.639744 4385318336 deprecation.py:506] From /Users/camesmith/miniconda/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0901 19:10:10.640556 4385318336 deprecation.py:506] From /Users/camesmith/miniconda/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Weirdly, I get an error unless I save the model and re-load it.\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "save_model(final_model, \"emotion_model\" )\n",
    "\n",
    "# Load back the model.\n",
    "serve_model = load_model(\"emotion_model\", compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 63s 17ms/sample - loss: 4.8371 - acc: 0.4419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.837142302751475, 0.44190583]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_conv = convert_format(X_test)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "serve_model.evaluate(X_test_conv, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = list(y_test)\n",
    "\n",
    "y_pred_ = serve_model.predict(X_test_conv)\n",
    "y_pred = [np.argmax(i) for i in y_pred_]\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training/validation accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
