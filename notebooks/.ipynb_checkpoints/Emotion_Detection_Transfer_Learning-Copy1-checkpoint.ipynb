{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Model\n",
    "A simple model that predicts a person's emotional state. This uses VGG16 for the earlier layers of the model and applies a custom (3 layer) network on top. I would like to predict 4 classes: happy, angry, sad, and scared/surprised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16\n",
    "https://github.com/tensorflow/models/blob/master/research/slim/nets/vgg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README      fer2013.bib fer2013.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Show where the data is stored.\n",
    "! ls ../data/face_data/fer2013/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/face_data/fer2013/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      "emotion    35887 non-null int64\n",
      "pixels     35887 non-null object\n",
      "Usage      35887 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three columns. \"Usage\" seems to be a pre-defined train/test split, probably balanced by gender/race/age.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    8989\n",
       "6    6198\n",
       "4    6077\n",
       "2    5121\n",
       "0    4953\n",
       "5    4002\n",
       "1     547\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 7 types of emotion. This is more than I care about and I will change them later.\n",
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PrivateTest     3589\n",
       "PublicTest      3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are two types of \"Test\" -- I'll combine them together\n",
    "df.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a numpy array.\n",
    "dfx = np.array(df)\n",
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The photos are stored as a string -- convert it  to list of integers.\n",
    "for i in range(len(dfx)):\n",
    "    dfx[i][1] = np.array([int(x) for x in dfx[i][1].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split.\n",
    "dfx_train = dfx[dfx[:, 2] == \"Training\"]\n",
    "dfx_test = dfx[dfx[:, 2] != \"Training\"]\n",
    "X_train, X_test, y_train, y_test = dfx_train[:, 1], dfx_test[:, 1], dfx_train[:, 0], dfx_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ignore the train/test split that was given in the data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X, y = dfx[:, 1], dfx[:, 0]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many pixels are in each image?\n",
    "len(dfx[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the dimensions of the picture (assuming its a square)?\n",
    "np.sqrt(2304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11cb77a58>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_train[1005].reshape(48, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Use VGG16 as a starting point [info](www.link.com), then add additional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a format that VGG16 will accept\n",
    "def convert_format(X_data):\n",
    "    # Normalize data to [0, 1] range\n",
    "    X_data = X_data / 255\n",
    "    \n",
    "    # Reshape to (n, 48, 48, 1)\n",
    "    x = np.array([i.reshape(48, 48, 1) for i in X_data])\n",
    "    \n",
    "    # Collect into one large list.\n",
    "    x = x.reshape(len(x) * 48 * 48 * 1)\n",
    "    \n",
    "    # Duplicate (three times) each item in the list\n",
    "    x = [i for i in x for _ in range(0, 3)]\n",
    "    \n",
    "    # Reshape into (n, 48, 48, 3)\n",
    "    x = np.array(x).reshape(len(X_data), 48, 48, 3)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert_format(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16 = VGG16(include_top=False, input_shape=(48, 48, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "vgg16.compile(optimizer=\"adam\", loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our data through the model to get its \"prediction.\"\n",
    "vgg16_output = vgg16.predict(X_input)\n",
    "\n",
    "# Expected (n, 1, 1, 512) shape.\n",
    "vgg16_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate our own model that takes the output of vgg16 and fits it to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "topLayerModel = Sequential()\n",
    "topLayerModel.add(Dense(256, input_shape=(512,), activation='relu'))\n",
    "topLayerModel.add(Dense(256, input_shape=(256,), activation='relu'))\n",
    "topLayerModel.add(Dropout(0.5))\n",
    "topLayerModel.add(Dense(128, input_shape=(256,), activation='relu'))\n",
    "topLayerModel.add(Dense(7, activation='softmax')) # 7 categories in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 1, 1, 512), (28709,))"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These need to be again reshaped to (n, 512) and (n, 7)\n",
    "vgg16_output.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the vgg16 output.\n",
    "vgg16_output_reshaped = vgg16_output.reshape(len(vgg16_output), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the category output to a 1-hot encoded vector.\n",
    "def one_hot_encode_y(y):\n",
    "    y = list(y)\n",
    "    y_one_hot = []\n",
    "    for i in y:\n",
    "        li = [0,0,0,0,0,0,0]\n",
    "        li[i] = 1\n",
    "        y_one_hot.append(li)\n",
    "    \n",
    "    return np.array(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 7)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped = one_hot_encode_y(y_train)\n",
    "y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 28709 samples\n",
      "Epoch 1/15\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 1.6602 - acc: 0.3425 - val_loss: 1.5618 - val_acc: 0.3872\n",
      "Epoch 2/15\n",
      "28709/28709 [==============================] - 7s 235us/step - loss: 1.5696 - acc: 0.3922 - val_loss: 1.5379 - val_acc: 0.4145\n",
      "Epoch 3/15\n",
      "28709/28709 [==============================] - 7s 243us/step - loss: 1.5327 - acc: 0.4107 - val_loss: 1.4734 - val_acc: 0.4368\n",
      "Epoch 4/15\n",
      "28709/28709 [==============================] - 9s 324us/step - loss: 1.5000 - acc: 0.4212 - val_loss: 1.4653 - val_acc: 0.4465\n",
      "Epoch 5/15\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.4653 - acc: 0.4360 - val_loss: 1.4190 - val_acc: 0.4562\n",
      "Epoch 6/15\n",
      "28709/28709 [==============================] - 11s 390us/step - loss: 1.4337 - acc: 0.4504 - val_loss: 1.3855 - val_acc: 0.4651\n",
      "Epoch 7/15\n",
      "28709/28709 [==============================] - 11s 374us/step - loss: 1.3994 - acc: 0.4648 - val_loss: 1.3391 - val_acc: 0.4916\n",
      "Epoch 8/15\n",
      "28709/28709 [==============================] - 10s 343us/step - loss: 1.3728 - acc: 0.4761 - val_loss: 1.3050 - val_acc: 0.5092\n",
      "Epoch 9/15\n",
      "28709/28709 [==============================] - 8s 285us/step - loss: 1.3434 - acc: 0.4889 - val_loss: 1.2771 - val_acc: 0.5208\n",
      "Epoch 10/15\n",
      "28709/28709 [==============================] - 8s 274us/step - loss: 1.3107 - acc: 0.4989 - val_loss: 1.2734 - val_acc: 0.5144\n",
      "Epoch 11/15\n",
      "28709/28709 [==============================] - 8s 264us/step - loss: 1.2823 - acc: 0.5121 - val_loss: 1.1935 - val_acc: 0.5512\n",
      "Epoch 12/15\n",
      "28709/28709 [==============================] - 8s 275us/step - loss: 1.2512 - acc: 0.5233 - val_loss: 1.1604 - val_acc: 0.5623\n",
      "Epoch 13/15\n",
      "28709/28709 [==============================] - 7s 261us/step - loss: 1.2169 - acc: 0.5391 - val_loss: 1.1379 - val_acc: 0.5680\n",
      "Epoch 14/15\n",
      "28709/28709 [==============================] - 7s 255us/step - loss: 1.1919 - acc: 0.5465 - val_loss: 1.0931 - val_acc: 0.5907\n",
      "Epoch 15/15\n",
      "28709/28709 [==============================] - 7s 259us/step - loss: 1.1642 - acc: 0.5608 - val_loss: 1.0772 - val_acc: 0.5933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c66bdaba8>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model.\n",
    "topLayerModel.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 28709 samples\n",
      "Epoch 1/100\n",
      "28709/28709 [==============================] - 8s 264us/step - loss: 1.1374 - acc: 0.5689 - val_loss: 1.0225 - val_acc: 0.6212\n",
      "Epoch 2/100\n",
      "28709/28709 [==============================] - 7s 261us/step - loss: 1.1160 - acc: 0.5816 - val_loss: 1.0117 - val_acc: 0.6202\n",
      "Epoch 3/100\n",
      "28709/28709 [==============================] - 7s 255us/step - loss: 1.0943 - acc: 0.5899 - val_loss: 0.9816 - val_acc: 0.6373\n",
      "Epoch 4/100\n",
      "28709/28709 [==============================] - 7s 253us/step - loss: 1.0748 - acc: 0.5947 - val_loss: 0.9588 - val_acc: 0.6450\n",
      "Epoch 5/100\n",
      "28709/28709 [==============================] - 7s 259us/step - loss: 1.0477 - acc: 0.6043 - val_loss: 0.9642 - val_acc: 0.6397\n",
      "Epoch 6/100\n",
      "28709/28709 [==============================] - 9s 328us/step - loss: 1.0272 - acc: 0.6110 - val_loss: 0.9455 - val_acc: 0.6438\n",
      "Epoch 7/100\n",
      "28709/28709 [==============================] - 10s 338us/step - loss: 1.0064 - acc: 0.6224 - val_loss: 0.8946 - val_acc: 0.6691\n",
      "Epoch 8/100\n",
      "28709/28709 [==============================] - 7s 247us/step - loss: 0.9889 - acc: 0.6289 - val_loss: 0.8737 - val_acc: 0.6754\n",
      "Epoch 9/100\n",
      "28709/28709 [==============================] - 9s 314us/step - loss: 0.9736 - acc: 0.6343 - val_loss: 0.8739 - val_acc: 0.6748\n",
      "Epoch 10/100\n",
      "28709/28709 [==============================] - 8s 271us/step - loss: 0.9498 - acc: 0.6435 - val_loss: 0.8493 - val_acc: 0.6842\n",
      "Epoch 11/100\n",
      "28709/28709 [==============================] - 7s 248us/step - loss: 0.9398 - acc: 0.6484 - val_loss: 0.8190 - val_acc: 0.6992\n",
      "Epoch 12/100\n",
      "28709/28709 [==============================] - 7s 249us/step - loss: 0.9218 - acc: 0.6560 - val_loss: 0.8133 - val_acc: 0.7004\n",
      "Epoch 13/100\n",
      "28709/28709 [==============================] - 7s 249us/step - loss: 0.9089 - acc: 0.6560 - val_loss: 0.8019 - val_acc: 0.7044\n",
      "Epoch 14/100\n",
      "28709/28709 [==============================] - 7s 241us/step - loss: 0.8953 - acc: 0.6638 - val_loss: 0.7849 - val_acc: 0.7151\n",
      "Epoch 15/100\n",
      "28709/28709 [==============================] - 7s 254us/step - loss: 0.8812 - acc: 0.6687 - val_loss: 0.7597 - val_acc: 0.7233\n",
      "Epoch 16/100\n",
      "28709/28709 [==============================] - 7s 244us/step - loss: 0.8617 - acc: 0.6761 - val_loss: 0.7639 - val_acc: 0.7151\n",
      "Epoch 17/100\n",
      "28709/28709 [==============================] - 7s 249us/step - loss: 0.8530 - acc: 0.6786 - val_loss: 0.7214 - val_acc: 0.7381\n",
      "Epoch 18/100\n",
      "28709/28709 [==============================] - 7s 253us/step - loss: 0.8377 - acc: 0.6860 - val_loss: 0.6945 - val_acc: 0.7478\n",
      "Epoch 19/100\n",
      "28709/28709 [==============================] - 7s 246us/step - loss: 0.8231 - acc: 0.6921 - val_loss: 0.6976 - val_acc: 0.7436\n",
      "Epoch 20/100\n",
      "28709/28709 [==============================] - 7s 247us/step - loss: 0.8116 - acc: 0.6962 - val_loss: 0.7105 - val_acc: 0.7369\n",
      "Epoch 21/100\n",
      "28709/28709 [==============================] - 7s 242us/step - loss: 0.8041 - acc: 0.7021 - val_loss: 0.6658 - val_acc: 0.7567\n",
      "Epoch 22/100\n",
      "28709/28709 [==============================] - 8s 265us/step - loss: 0.7942 - acc: 0.7028 - val_loss: 0.6721 - val_acc: 0.7588\n",
      "Epoch 23/100\n",
      "28709/28709 [==============================] - 7s 251us/step - loss: 0.7861 - acc: 0.7072 - val_loss: 0.6733 - val_acc: 0.7516\n",
      "Epoch 24/100\n",
      "28709/28709 [==============================] - 8s 272us/step - loss: 0.7727 - acc: 0.7127 - val_loss: 0.6361 - val_acc: 0.7700\n",
      "Epoch 25/100\n",
      "28709/28709 [==============================] - 7s 250us/step - loss: 0.7628 - acc: 0.7132 - val_loss: 0.6355 - val_acc: 0.7710\n",
      "Epoch 26/100\n",
      "28709/28709 [==============================] - 7s 240us/step - loss: 0.7499 - acc: 0.7220 - val_loss: 0.6295 - val_acc: 0.7696\n",
      "Epoch 27/100\n",
      "28709/28709 [==============================] - 7s 242us/step - loss: 0.7442 - acc: 0.7216 - val_loss: 0.6182 - val_acc: 0.7775\n",
      "Epoch 28/100\n",
      "28709/28709 [==============================] - 7s 252us/step - loss: 0.7318 - acc: 0.7257 - val_loss: 0.6094 - val_acc: 0.7803\n",
      "Epoch 29/100\n",
      "28709/28709 [==============================] - 8s 280us/step - loss: 0.7239 - acc: 0.7295 - val_loss: 0.5837 - val_acc: 0.7888\n",
      "Epoch 30/100\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.7220 - acc: 0.7307 - val_loss: 0.5866 - val_acc: 0.7884\n",
      "Epoch 31/100\n",
      "28709/28709 [==============================] - 7s 254us/step - loss: 0.7039 - acc: 0.7375 - val_loss: 0.5738 - val_acc: 0.7907\n",
      "Epoch 32/100\n",
      "28709/28709 [==============================] - 7s 247us/step - loss: 0.6944 - acc: 0.7413 - val_loss: 0.5627 - val_acc: 0.7948\n",
      "Epoch 33/100\n",
      "28709/28709 [==============================] - 7s 258us/step - loss: 0.6964 - acc: 0.7406 - val_loss: 0.5478 - val_acc: 0.8050\n",
      "Epoch 34/100\n",
      "28709/28709 [==============================] - 7s 256us/step - loss: 0.6807 - acc: 0.7445 - val_loss: 0.5648 - val_acc: 0.7942\n",
      "Epoch 35/100\n",
      "28709/28709 [==============================] - 8s 263us/step - loss: 0.6795 - acc: 0.7459 - val_loss: 0.5472 - val_acc: 0.7998\n",
      "Epoch 36/100\n",
      "28709/28709 [==============================] - 8s 271us/step - loss: 0.6662 - acc: 0.7499 - val_loss: 0.5330 - val_acc: 0.8092\n",
      "Epoch 37/100\n",
      "28709/28709 [==============================] - 8s 278us/step - loss: 0.6573 - acc: 0.7535 - val_loss: 0.5545 - val_acc: 0.7988\n",
      "Epoch 38/100\n",
      "28709/28709 [==============================] - 7s 256us/step - loss: 0.6561 - acc: 0.7537 - val_loss: 0.5153 - val_acc: 0.8117\n",
      "Epoch 39/100\n",
      "28709/28709 [==============================] - 8s 267us/step - loss: 0.6534 - acc: 0.7554 - val_loss: 0.4866 - val_acc: 0.8278\n",
      "Epoch 40/100\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.6348 - acc: 0.7646 - val_loss: 0.5193 - val_acc: 0.8130\n",
      "Epoch 41/100\n",
      "28709/28709 [==============================] - 8s 281us/step - loss: 0.6309 - acc: 0.7663 - val_loss: 0.4998 - val_acc: 0.8163\n",
      "Epoch 42/100\n",
      "28709/28709 [==============================] - 8s 288us/step - loss: 0.6373 - acc: 0.7599 - val_loss: 0.4985 - val_acc: 0.8202\n",
      "Epoch 43/100\n",
      "28709/28709 [==============================] - 8s 279us/step - loss: 0.6161 - acc: 0.7694 - val_loss: 0.4831 - val_acc: 0.8255\n",
      "Epoch 44/100\n",
      "28709/28709 [==============================] - 7s 251us/step - loss: 0.6178 - acc: 0.7703 - val_loss: 0.4912 - val_acc: 0.8183\n",
      "Epoch 45/100\n",
      "28709/28709 [==============================] - 7s 246us/step - loss: 0.6096 - acc: 0.7714 - val_loss: 0.5024 - val_acc: 0.8169\n",
      "Epoch 46/100\n",
      "28709/28709 [==============================] - 7s 248us/step - loss: 0.6051 - acc: 0.7761 - val_loss: 0.4815 - val_acc: 0.8230\n",
      "Epoch 47/100\n",
      "28709/28709 [==============================] - 7s 250us/step - loss: 0.6006 - acc: 0.7766 - val_loss: 0.4799 - val_acc: 0.8231\n",
      "Epoch 48/100\n",
      "28709/28709 [==============================] - 7s 249us/step - loss: 0.5879 - acc: 0.7815 - val_loss: 0.4711 - val_acc: 0.8269\n",
      "Epoch 49/100\n",
      "28709/28709 [==============================] - 7s 248us/step - loss: 0.5998 - acc: 0.7775 - val_loss: 0.4525 - val_acc: 0.8370\n",
      "Epoch 50/100\n",
      "28709/28709 [==============================] - 7s 251us/step - loss: 0.5757 - acc: 0.7872 - val_loss: 0.4537 - val_acc: 0.8400\n",
      "Epoch 51/100\n",
      "28709/28709 [==============================] - 8s 283us/step - loss: 0.5749 - acc: 0.7862 - val_loss: 0.4383 - val_acc: 0.8440\n",
      "Epoch 52/100\n",
      "28709/28709 [==============================] - 8s 275us/step - loss: 0.5767 - acc: 0.7844 - val_loss: 0.4713 - val_acc: 0.8275\n",
      "Epoch 53/100\n",
      "28709/28709 [==============================] - 8s 280us/step - loss: 0.5650 - acc: 0.7898 - val_loss: 0.4686 - val_acc: 0.8308\n",
      "Epoch 54/100\n",
      "28709/28709 [==============================] - 9s 316us/step - loss: 0.5637 - acc: 0.7896 - val_loss: 0.4141 - val_acc: 0.8529\n",
      "Epoch 55/100\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.5540 - acc: 0.7931 - val_loss: 0.4313 - val_acc: 0.8457\n",
      "Epoch 56/100\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.5461 - acc: 0.7961 - val_loss: 0.4080 - val_acc: 0.8562\n",
      "Epoch 57/100\n",
      "28709/28709 [==============================] - 8s 284us/step - loss: 0.5486 - acc: 0.7973 - val_loss: 0.4047 - val_acc: 0.8584\n",
      "Epoch 58/100\n",
      "28709/28709 [==============================] - 8s 282us/step - loss: 0.5410 - acc: 0.7991 - val_loss: 0.3967 - val_acc: 0.8582\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 8s 283us/step - loss: 0.5481 - acc: 0.7978 - val_loss: 0.4064 - val_acc: 0.8549\n",
      "Epoch 60/100\n",
      "28709/28709 [==============================] - 8s 289us/step - loss: 0.5292 - acc: 0.8032 - val_loss: 0.3674 - val_acc: 0.8724\n",
      "Epoch 61/100\n",
      "28709/28709 [==============================] - 8s 287us/step - loss: 0.5290 - acc: 0.8007 - val_loss: 0.3645 - val_acc: 0.8760\n",
      "Epoch 62/100\n",
      "28709/28709 [==============================] - 8s 287us/step - loss: 0.5264 - acc: 0.8029 - val_loss: 0.3985 - val_acc: 0.8564\n",
      "Epoch 63/100\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.5278 - acc: 0.8032 - val_loss: 0.3708 - val_acc: 0.8660\n",
      "Epoch 64/100\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.5193 - acc: 0.8054 - val_loss: 0.3913 - val_acc: 0.8625\n",
      "Epoch 65/100\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.5225 - acc: 0.8029 - val_loss: 0.3856 - val_acc: 0.8601\n",
      "Epoch 66/100\n",
      "28709/28709 [==============================] - 8s 289us/step - loss: 0.5065 - acc: 0.8097 - val_loss: 0.3834 - val_acc: 0.8629\n",
      "Epoch 67/100\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.5111 - acc: 0.8096 - val_loss: 0.3654 - val_acc: 0.8710\n",
      "Epoch 68/100\n",
      "28709/28709 [==============================] - 8s 281us/step - loss: 0.5038 - acc: 0.8136 - val_loss: 0.3559 - val_acc: 0.8733\n",
      "Epoch 69/100\n",
      "28709/28709 [==============================] - 8s 282us/step - loss: 0.5066 - acc: 0.8114 - val_loss: 0.3625 - val_acc: 0.8708\n",
      "Epoch 70/100\n",
      "28709/28709 [==============================] - 8s 288us/step - loss: 0.4921 - acc: 0.8155 - val_loss: 0.3367 - val_acc: 0.8809\n",
      "Epoch 71/100\n",
      "28709/28709 [==============================] - 8s 285us/step - loss: 0.4909 - acc: 0.8162 - val_loss: 0.3395 - val_acc: 0.8828\n",
      "Epoch 72/100\n",
      "28709/28709 [==============================] - 8s 284us/step - loss: 0.4998 - acc: 0.8134 - val_loss: 0.3384 - val_acc: 0.8812\n",
      "Epoch 73/100\n",
      "28709/28709 [==============================] - 8s 284us/step - loss: 0.4928 - acc: 0.8171 - val_loss: 0.3217 - val_acc: 0.8926\n",
      "Epoch 74/100\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.4852 - acc: 0.8208 - val_loss: 0.3471 - val_acc: 0.8793\n",
      "Epoch 75/100\n",
      "28709/28709 [==============================] - 8s 263us/step - loss: 0.4804 - acc: 0.8225 - val_loss: 0.3237 - val_acc: 0.8884\n",
      "Epoch 76/100\n",
      "28709/28709 [==============================] - 7s 257us/step - loss: 0.4768 - acc: 0.8240 - val_loss: 0.3202 - val_acc: 0.8897\n",
      "Epoch 77/100\n",
      "28709/28709 [==============================] - 7s 252us/step - loss: 0.4744 - acc: 0.8217 - val_loss: 0.3367 - val_acc: 0.8800\n",
      "Epoch 78/100\n",
      "28709/28709 [==============================] - 7s 260us/step - loss: 0.4696 - acc: 0.8239 - val_loss: 0.3368 - val_acc: 0.8818\n",
      "Epoch 79/100\n",
      "28709/28709 [==============================] - 7s 257us/step - loss: 0.4712 - acc: 0.8235 - val_loss: 0.3277 - val_acc: 0.8869\n",
      "Epoch 80/100\n",
      "28709/28709 [==============================] - 7s 253us/step - loss: 0.4697 - acc: 0.8270 - val_loss: 0.3390 - val_acc: 0.8819\n",
      "Epoch 81/100\n",
      "28709/28709 [==============================] - 7s 253us/step - loss: 0.4551 - acc: 0.8317 - val_loss: 0.3055 - val_acc: 0.8957\n",
      "Epoch 82/100\n",
      "28709/28709 [==============================] - 7s 253us/step - loss: 0.4621 - acc: 0.8277 - val_loss: 0.3337 - val_acc: 0.8832\n",
      "Epoch 83/100\n",
      "28709/28709 [==============================] - 7s 261us/step - loss: 0.4573 - acc: 0.8283 - val_loss: 0.3044 - val_acc: 0.8963\n",
      "Epoch 84/100\n",
      "28709/28709 [==============================] - 7s 258us/step - loss: 0.4506 - acc: 0.8323 - val_loss: 0.3429 - val_acc: 0.8762\n",
      "Epoch 85/100\n",
      "28709/28709 [==============================] - 7s 261us/step - loss: 0.4529 - acc: 0.8302 - val_loss: 0.3244 - val_acc: 0.8858\n",
      "Epoch 86/100\n",
      "28709/28709 [==============================] - 8s 265us/step - loss: 0.4523 - acc: 0.8335 - val_loss: 0.3024 - val_acc: 0.8959\n",
      "Epoch 87/100\n",
      "28709/28709 [==============================] - 8s 267us/step - loss: 0.4413 - acc: 0.8348 - val_loss: 0.2800 - val_acc: 0.9042\n",
      "Epoch 88/100\n",
      "28709/28709 [==============================] - 10s 365us/step - loss: 0.4362 - acc: 0.8355 - val_loss: 0.3239 - val_acc: 0.8854\n",
      "Epoch 89/100\n",
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.4515 - acc: 0.8332 - val_loss: 0.2883 - val_acc: 0.9030\n",
      "Epoch 90/100\n",
      "28709/28709 [==============================] - 13s 438us/step - loss: 0.4239 - acc: 0.8418 - val_loss: 0.2927 - val_acc: 0.8965\n",
      "Epoch 91/100\n",
      "28709/28709 [==============================] - 12s 431us/step - loss: 0.4332 - acc: 0.8379 - val_loss: 0.3203 - val_acc: 0.8850\n",
      "Epoch 92/100\n",
      "28709/28709 [==============================] - 12s 423us/step - loss: 0.4368 - acc: 0.8369 - val_loss: 0.2672 - val_acc: 0.9117\n",
      "Epoch 93/100\n",
      "28709/28709 [==============================] - 12s 428us/step - loss: 0.4364 - acc: 0.8385 - val_loss: 0.2931 - val_acc: 0.8999\n",
      "Epoch 94/100\n",
      "28709/28709 [==============================] - 12s 435us/step - loss: 0.4295 - acc: 0.8400 - val_loss: 0.3017 - val_acc: 0.8948\n",
      "Epoch 95/100\n",
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.4240 - acc: 0.8407 - val_loss: 0.3102 - val_acc: 0.8913\n",
      "Epoch 96/100\n",
      "28709/28709 [==============================] - 13s 437us/step - loss: 0.4335 - acc: 0.8379 - val_loss: 0.2896 - val_acc: 0.9022\n",
      "Epoch 97/100\n",
      "28709/28709 [==============================] - 13s 436us/step - loss: 0.4226 - acc: 0.8434 - val_loss: 0.2917 - val_acc: 0.8986\n",
      "Epoch 98/100\n",
      "28709/28709 [==============================] - 13s 440us/step - loss: 0.4154 - acc: 0.8433 - val_loss: 0.2824 - val_acc: 0.9050\n",
      "Epoch 99/100\n",
      "28709/28709 [==============================] - 13s 439us/step - loss: 0.4145 - acc: 0.8431 - val_loss: 0.3001 - val_acc: 0.8929\n",
      "Epoch 100/100\n",
      "28709/28709 [==============================] - 13s 436us/step - loss: 0.4172 - acc: 0.8449 - val_loss: 0.2703 - val_acc: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c66bdad30>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model. After 500 epochs the accuracy is 0.95 and loss is 0.07.\n",
    "topLayerModel.fit(vgg16_output_reshaped, y_reshaped,\n",
    "          validation_data=(vgg16_output_reshaped, y_reshaped),\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 48, 48, 3)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the performance on the test set.\n",
    "X_test = convert_format(X_test)\n",
    "y_test = one_hot_encode_y(y_test)\n",
    "\n",
    "vgg16_output_test = vgg16.predict(X_test)\n",
    "vgg16_output_test = vgg16_output_test.reshape(len(vgg16_output_test), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = topLayerModel.predict(vgg16_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = 0\n",
    "for i in range(len(preds)):\n",
    "    if list(preds[i]) != list(y_test[i]):\n",
    "        diff += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([1, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0], np.array(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5675675675675675"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [np.argmax(i) for i in y_test]\n",
    "y_pred = [np.argmax(i) for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[394,  13, 103, 155, 144,  44, 105],\n",
       "       [ 21,  47,   9,  13,   9,   2,  10],\n",
       "       [174,   6, 375, 121, 168,  84,  96],\n",
       "       [240,  12, 132, 913, 208,  75, 194],\n",
       "       [239,  12, 151, 210, 430,  40, 165],\n",
       "       [ 52,   2,  85,  77,  35, 526,  54],\n",
       "       [185,   3, 105, 242, 192,  55, 451]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute confusion matrix.\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Pipeline\n",
    "Build a scoring pipeline to combine the two models, score the test set, and check out some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two models into a single pipeline.\n",
    "def score_face(image):\n",
    "    #####\n",
    "\n",
    "    # inputs = Input(shape=(48, 48, 3))\n",
    "    # vg_output = vgg16(inputs)\n",
    "    # model_predictions = topLayerModel(vg_output)\n",
    "    # final_model = Model(input=inputs, output=model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48, 3)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.8672116e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.2350287e-01,\n",
       "          0.0000000e+00, 4.4080102e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 8.0790287e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          6.9606259e-02, 1.2571573e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          5.7623263e-02, 0.0000000e+00, 9.8083131e-02, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.0196807e-01,\n",
       "          2.2029355e-01, 0.0000000e+00, 0.0000000e+00, 9.0411156e-01,\n",
       "          3.2354448e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3570900e-01,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 1.3171406e-02, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 1.6100297e-02, 0.0000000e+00,\n",
       "          0.0000000e+00, 5.4753721e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 1.7530822e+00, 2.4827879e-02, 0.0000000e+00,\n",
       "          2.7075562e-01, 0.0000000e+00, 2.1191598e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          9.1469806e-01, 1.6307144e+00, 1.1585639e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 2.1785700e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 5.6876767e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          1.5730425e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 8.5787916e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 9.3293315e-01, 1.2535585e-01, 9.7444592e+00,\n",
       "          6.7686224e-01, 7.1134377e-01, 1.5438552e-01, 5.7595700e-01,\n",
       "          1.1087140e+00, 0.0000000e+00, 0.0000000e+00, 1.0004616e-01,\n",
       "          8.5594046e-01, 4.6549645e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 5.0654963e-02,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.7150952e-01,\n",
       "          4.5813632e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 4.7088128e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 1.7672616e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 1.5901734e-01, 1.6674238e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 1.4985992e-01, 0.0000000e+00,\n",
       "          4.6082115e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          9.9247441e-02, 0.0000000e+00, 0.0000000e+00, 3.3164501e-01,\n",
       "          7.8424877e-01, 0.0000000e+00, 1.2290881e+00, 0.0000000e+00,\n",
       "          4.3643570e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.5921135e-01,\n",
       "          0.0000000e+00, 0.0000000e+00, 4.8954430e-01, 8.2668984e-01,\n",
       "          2.6744261e-02, 0.0000000e+00, 0.0000000e+00, 1.7953897e+00,\n",
       "          8.0383646e-01, 2.2648400e-02, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 3.0205041e-01, 7.0648074e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6359363e-01,\n",
       "          0.0000000e+00, 0.0000000e+00, 7.6790273e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 1.6753902e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          3.6424497e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 2.1234672e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.2794600e-01,\n",
       "          0.0000000e+00, 1.3992682e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 5.9774411e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.1227473e-01,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2847210e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          2.8464001e-01, 0.0000000e+00, 4.2857891e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 1.1483077e+00, 9.7050411e-01, 0.0000000e+00,\n",
       "          3.8846985e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 6.8300873e-01, 6.1275832e-02,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          4.0354699e-01, 0.0000000e+00, 0.0000000e+00, 6.6936217e-02,\n",
       "          0.0000000e+00, 0.0000000e+00, 1.1533093e-02, 0.0000000e+00,\n",
       "          0.0000000e+00, 1.3914913e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          6.0284472e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.5612473e-01,\n",
       "          0.0000000e+00, 1.7851928e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 7.1742356e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          2.1274414e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          1.6634458e-01, 5.8210379e-01, 1.6579331e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.7977298e-02,\n",
       "          0.0000000e+00, 0.0000000e+00, 5.5853456e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 2.4812473e-01, 0.0000000e+00,\n",
       "          4.0614066e-01, 9.1627255e-02, 0.0000000e+00, 3.4078875e-01,\n",
       "          0.0000000e+00, 1.3651955e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 2.9782282e-02, 0.0000000e+00, 0.0000000e+00,\n",
       "          3.9769015e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 7.1947388e-03, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 3.2787638e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          5.7871461e-01, 0.0000000e+00, 0.0000000e+00, 8.8501030e-01,\n",
       "          8.0882168e-01, 2.6519101e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          2.7759007e-01, 7.5592525e-02, 0.0000000e+00, 7.8036052e-01,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 8.8907480e-02, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          3.7981790e-01, 0.0000000e+00, 2.4889123e-01, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          1.8922681e-01, 0.0000000e+00, 1.6277836e-01, 0.0000000e+00,\n",
       "          2.5036472e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 9.2185920e-01, 6.1446947e-01,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          4.6092104e-02, 6.0230698e-02, 4.0909800e-01, 3.0815509e-01,\n",
       "          2.2485425e-01, 0.0000000e+00, 5.5857098e-01, 0.0000000e+00,\n",
       "          2.3061934e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 2.5972974e-01, 0.0000000e+00]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.predict(X_input[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
