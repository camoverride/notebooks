{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLYR Data Science Challenge\n",
    "\n",
    "_Cameron Smith_\n",
    "\n",
    "June 2018\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "1. Overview\n",
    "2. Understand the data\n",
    "    * 2.1 Import libraries\n",
    "    * 2.2 Load the data\n",
    "    * 2.3 Summaries\n",
    "        * 2.3.1 Airport data\n",
    "        * 2.3.2 Booking data\n",
    "        * 2.3.3 Search data\n",
    "        * 2.3.4 Columns in common\n",
    "3. Data preparation\n",
    "    * 3.1 Overview\n",
    "        * 3.1.1 Existing features\n",
    "        * 3.1.2 Features to be created\n",
    "    * 3.2 Existing features\n",
    "        * 3.2.1 Handle missing values\n",
    "        * 3.2.2 Convert to correct format\n",
    "        * 3.2.3 Bucketize cabin variable\n",
    "        * 3.2.4 Convert currency\n",
    "    * 3.3 Engineer new features\n",
    "        * 3.3.1 Distance traveled\n",
    "        * 3.3.2 Was the airfare booked?\n",
    "        * 3.3.3 Was the airfare one way?\n",
    "        * 3.3.4 Depart diff\n",
    "        * 3.3.5 Various date features\n",
    "    * 3.4 Convert categorical data to dummy variables\n",
    "    * 3.5 Scale numerical data\n",
    "    * 3.6 Drop unneeded features\n",
    "    * 3.7 Visualize data\n",
    "4. Modeling\n",
    "    * 4.1 Build the model\n",
    "5. Evaluation\n",
    "    * 5.1 Model performance\n",
    "    * 5.2 Feature importance\n",
    "    * 5.3 Future directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview\n",
    "I've been asked to perform two tasks: (1) *predict the value of an offered airfare* and (2) *predict which airfares are booked*. I have been provided with three datasets and a useful document that describes the meaning of the variables in each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Understand the data\n",
    "## 2.1 Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%sh\n",
    "pip install requests\n",
    "pip install currencyconverter\n",
    "pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import currencyconverter\n",
    "import requests\n",
    "import geocoder\n",
    "#from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load the data\n",
    "\n",
    "Now I'll peek at the data I've been given and read it into a form that's easy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport_data.csv   \u001b[34mcurrencyconverter\u001b[m\u001b[m/ derp123.ipynb      \u001b[34mvenv\u001b[m\u001b[m/\r\n",
      "booking_data.csv   derp.py            search_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "%% capture\n",
    "airport_data = pd.read_csv('airport_data.csv')\n",
    "booking_data = pd.read_csv('booking_data.csv')\n",
    "search_data = pd.read_csv('search_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Airport Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5823 entries, 0 to 5822\n",
      "Data columns (total 9 columns):\n",
      "iata_code         5823 non-null object\n",
      "city              5823 non-null object\n",
      "country           5823 non-null object\n",
      "latitude          5766 non-null float64\n",
      "longitude         5766 non-null float64\n",
      "altitude          5690 non-null float64\n",
      "timezone          5760 non-null float64\n",
      "dst               5704 non-null object\n",
      "aggregate_code    5761 non-null float64\n",
      "dtypes: float64(5), object(4)\n",
      "memory usage: 409.5+ KB\n"
     ]
    }
   ],
   "source": [
    "airport_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iata_code', 'city', 'country', 'latitude', 'longitude', 'altitude',\n",
       "       'timezone', 'dst', 'aggregate_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iata_code</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>timezone</th>\n",
       "      <th>dst</th>\n",
       "      <th>aggregate_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.7142</td>\n",
       "      <td>-74.00580</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QSF</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>United States</td>\n",
       "      <td>41.8836</td>\n",
       "      <td>-87.63170</td>\n",
       "      <td>596.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAR</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>48.8564</td>\n",
       "      <td>2.35222</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>38.8894</td>\n",
       "      <td>-77.03530</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iata_code           city        country  latitude  longitude  altitude  \\\n",
       "0       NYC       New York  United States   40.7142  -74.00580      31.0   \n",
       "1       QSF  San Francisco  United States       NaN        NaN       NaN   \n",
       "2       CHI        Chicago  United States   41.8836  -87.63170     596.0   \n",
       "3       PAR          Paris         France   48.8564    2.35222     107.0   \n",
       "4       WAS     Washington  United States   38.8894  -77.03530      25.0   \n",
       "\n",
       "   timezone  dst  aggregate_code  \n",
       "0      -5.0    A             1.0  \n",
       "1      -8.0  NaN             1.0  \n",
       "2      -6.0    A             1.0  \n",
       "3       1.0    E             1.0  \n",
       "4      -5.0    A             1.0  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Booking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16854 entries, 0 to 16853\n",
      "Data columns (total 25 columns):\n",
      "booking_id              16854 non-null object\n",
      "booking_time            16854 non-null object\n",
      "currency                16854 non-null object\n",
      "destination             16854 non-null object\n",
      "booking_user_id         16854 non-null object\n",
      "language                16854 non-null object\n",
      "origin                  16854 non-null object\n",
      "partner_id              16854 non-null int64\n",
      "passengers              16854 non-null int64\n",
      "pos                     15504 non-null object\n",
      "session_id              16854 non-null object\n",
      "user_agent              13485 non-null object\n",
      "num_requests            16854 non-null int64\n",
      "fare                    16854 non-null float64\n",
      "supplier                16854 non-null int64\n",
      "cabin_class             16854 non-null object\n",
      "carrier_1               16854 non-null object\n",
      "carrier_2               13378 non-null object\n",
      "flight_num_1            16854 non-null object\n",
      "flight_num_2            13378 non-null object\n",
      "departure_datetime_1    16854 non-null object\n",
      "arrival_datetime_1      16854 non-null object\n",
      "departure_datetime_2    13378 non-null object\n",
      "arrival_datetime_2      13378 non-null object\n",
      "itinerary_id            16854 non-null object\n",
      "dtypes: float64(1), int64(4), object(20)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "booking_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partner_id</th>\n",
       "      <th>passengers</th>\n",
       "      <th>num_requests</th>\n",
       "      <th>fare</th>\n",
       "      <th>supplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>partner_id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019721</td>\n",
       "      <td>-0.099739</td>\n",
       "      <td>0.030768</td>\n",
       "      <td>-0.707887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passengers</th>\n",
       "      <td>0.019721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>-0.014235</td>\n",
       "      <td>-0.027118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_requests</th>\n",
       "      <td>-0.099739</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045988</td>\n",
       "      <td>0.166444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>0.030768</td>\n",
       "      <td>-0.014235</td>\n",
       "      <td>0.045988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supplier</th>\n",
       "      <td>-0.707887</td>\n",
       "      <td>-0.027118</td>\n",
       "      <td>0.166444</td>\n",
       "      <td>-0.035824</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              partner_id  passengers  num_requests      fare  supplier\n",
       "partner_id      1.000000    0.019721     -0.099739  0.030768 -0.707887\n",
       "passengers      0.019721    1.000000     -0.006152 -0.014235 -0.027118\n",
       "num_requests   -0.099739   -0.006152      1.000000  0.045988  0.166444\n",
       "fare            0.030768   -0.014235      0.045988  1.000000 -0.035824\n",
       "supplier       -0.707887   -0.027118      0.166444 -0.035824  1.000000"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['booking_id', 'booking_time', 'currency', 'destination',\n",
       "       'booking_user_id', 'language', 'origin', 'partner_id', 'passengers',\n",
       "       'pos', 'session_id', 'user_agent', 'num_requests', 'fare', 'supplier',\n",
       "       'cabin_class', 'carrier_1', 'carrier_2', 'flight_num_1', 'flight_num_2',\n",
       "       'departure_datetime_1', 'arrival_datetime_1', 'departure_datetime_2',\n",
       "       'arrival_datetime_2', 'itinerary_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booking_id</th>\n",
       "      <th>booking_time</th>\n",
       "      <th>currency</th>\n",
       "      <th>destination</th>\n",
       "      <th>booking_user_id</th>\n",
       "      <th>language</th>\n",
       "      <th>origin</th>\n",
       "      <th>partner_id</th>\n",
       "      <th>passengers</th>\n",
       "      <th>pos</th>\n",
       "      <th>...</th>\n",
       "      <th>cabin_class</th>\n",
       "      <th>carrier_1</th>\n",
       "      <th>carrier_2</th>\n",
       "      <th>flight_num_1</th>\n",
       "      <th>flight_num_2</th>\n",
       "      <th>departure_datetime_1</th>\n",
       "      <th>arrival_datetime_1</th>\n",
       "      <th>departure_datetime_2</th>\n",
       "      <th>arrival_datetime_2</th>\n",
       "      <th>itinerary_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ec12305-ba84-419a-8fc0-6aaf78d9abb2</td>\n",
       "      <td>2017-02-01 00:00:46</td>\n",
       "      <td>USD</td>\n",
       "      <td>SJD</td>\n",
       "      <td>36195bda-ec40-4907-9428-c4fe11bd87fa</td>\n",
       "      <td>en</td>\n",
       "      <td>LAX</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA237</td>\n",
       "      <td>AA237</td>\n",
       "      <td>2017-05-30T08:35:00</td>\n",
       "      <td>2017-05-30T11:58:00</td>\n",
       "      <td>2017-06-03T13:00:00</td>\n",
       "      <td>2017-06-03T14:36:00</td>\n",
       "      <td>c53826cf-1fba-42a6-a765-941628e1901e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5eb6e42e-bcdc-4b0a-8b3a-744b4ef1d805</td>\n",
       "      <td>2017-02-01 00:01:03</td>\n",
       "      <td>USD</td>\n",
       "      <td>LAX</td>\n",
       "      <td>025ee32b-2a0b-4987-b275-893f148ab259</td>\n",
       "      <td>en</td>\n",
       "      <td>CMH</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-29T16:35:00</td>\n",
       "      <td>2017-03-29T18:53:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2e3afcd8-7d56-4b49-a71b-f85c23e1b807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3db456d-538d-4f98-a2a0-d6bcedf3b459</td>\n",
       "      <td>2017-02-01 00:01:04</td>\n",
       "      <td>USD</td>\n",
       "      <td>MCO</td>\n",
       "      <td>f69465d7-cdb2-4dd0-98ad-6362423a8dc3</td>\n",
       "      <td>en</td>\n",
       "      <td>EGE</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>UA; UA</td>\n",
       "      <td>UA; UA</td>\n",
       "      <td>UA4475; UA564</td>\n",
       "      <td>UA1191; UA1252</td>\n",
       "      <td>2017-02-10T07:52:00; 2017-02-10T11:00:00</td>\n",
       "      <td>2017-02-10T09:03:00; 2017-02-10T16:31:00</td>\n",
       "      <td>2017-02-13T08:47:00; 2017-02-13T11:40:00</td>\n",
       "      <td>2017-02-13T10:30:00; 2017-02-13T13:41:00</td>\n",
       "      <td>619b0f7c-825f-47b1-a191-300862feff80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b9133358-7e81-4aea-bce8-8c79823c4ac8</td>\n",
       "      <td>2017-02-01 00:01:12</td>\n",
       "      <td>USD</td>\n",
       "      <td>LHR</td>\n",
       "      <td>36ba8a8c-8c47-4dc6-bd70-0b3ae071c8cf</td>\n",
       "      <td>en</td>\n",
       "      <td>PHX</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>DL; DL</td>\n",
       "      <td>DL; DL</td>\n",
       "      <td>DL5852; DL4414</td>\n",
       "      <td>DL11; DL1516</td>\n",
       "      <td>2017-05-10T13:13:00; 2017-05-10T18:30:00</td>\n",
       "      <td>2017-05-10T14:45:00; 2017-05-11T12:55:00</td>\n",
       "      <td>2017-05-28T12:55:00; 2017-05-28T17:50:00</td>\n",
       "      <td>2017-05-28T16:05:00; 2017-05-28T19:11:00</td>\n",
       "      <td>37a44686-8347-4c72-8690-c9432349f9a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4699db09-65c2-492f-9aa6-c9e7734a60c1</td>\n",
       "      <td>2017-02-01 00:01:25</td>\n",
       "      <td>USD</td>\n",
       "      <td>LHR</td>\n",
       "      <td>b1a66917-ca3e-457e-8bb2-79b6cd86ca7c</td>\n",
       "      <td>en</td>\n",
       "      <td>SFO</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>TP; TP; TP</td>\n",
       "      <td>TP; TP; TP</td>\n",
       "      <td>TP8052; TP218; TP352</td>\n",
       "      <td>TP353; TP209; TP8051</td>\n",
       "      <td>2017-03-06T08:00:00; 2017-03-06T20:00:00; 2017...</td>\n",
       "      <td>2017-03-06T16:35:00; 2017-03-07T07:15:00; 2017...</td>\n",
       "      <td>2017-03-09T06:00:00; 2017-03-09T16:50:00; 2017...</td>\n",
       "      <td>2017-03-09T08:35:00; 2017-03-09T20:15:00; 2017...</td>\n",
       "      <td>b84a4eca-fd5f-4794-afaa-e1d0e7231537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             booking_id         booking_time currency  \\\n",
       "0  7ec12305-ba84-419a-8fc0-6aaf78d9abb2  2017-02-01 00:00:46      USD   \n",
       "1  5eb6e42e-bcdc-4b0a-8b3a-744b4ef1d805  2017-02-01 00:01:03      USD   \n",
       "2  d3db456d-538d-4f98-a2a0-d6bcedf3b459  2017-02-01 00:01:04      USD   \n",
       "3  b9133358-7e81-4aea-bce8-8c79823c4ac8  2017-02-01 00:01:12      USD   \n",
       "4  4699db09-65c2-492f-9aa6-c9e7734a60c1  2017-02-01 00:01:25      USD   \n",
       "\n",
       "  destination                       booking_user_id language origin  \\\n",
       "0         SJD  36195bda-ec40-4907-9428-c4fe11bd87fa       en    LAX   \n",
       "1         LAX  025ee32b-2a0b-4987-b275-893f148ab259       en    CMH   \n",
       "2         MCO  f69465d7-cdb2-4dd0-98ad-6362423a8dc3       en    EGE   \n",
       "3         LHR  36ba8a8c-8c47-4dc6-bd70-0b3ae071c8cf       en    PHX   \n",
       "4         LHR  b1a66917-ca3e-457e-8bb2-79b6cd86ca7c       en    SFO   \n",
       "\n",
       "   partner_id  passengers pos                  ...                   \\\n",
       "0          91           1  US                  ...                    \n",
       "1          91           1  US                  ...                    \n",
       "2          91           1  US                  ...                    \n",
       "3          91           2  US                  ...                    \n",
       "4          91           1  US                  ...                    \n",
       "\n",
       "  cabin_class   carrier_1   carrier_2          flight_num_1  \\\n",
       "0     economy          AA          AA                 AA237   \n",
       "1     economy          AA         NaN                 AA659   \n",
       "2     economy      UA; UA      UA; UA         UA4475; UA564   \n",
       "3     economy      DL; DL      DL; DL        DL5852; DL4414   \n",
       "4     economy  TP; TP; TP  TP; TP; TP  TP8052; TP218; TP352   \n",
       "\n",
       "           flight_num_2                               departure_datetime_1  \\\n",
       "0                 AA237                                2017-05-30T08:35:00   \n",
       "1                   NaN                                2017-03-29T16:35:00   \n",
       "2        UA1191; UA1252           2017-02-10T07:52:00; 2017-02-10T11:00:00   \n",
       "3          DL11; DL1516           2017-05-10T13:13:00; 2017-05-10T18:30:00   \n",
       "4  TP353; TP209; TP8051  2017-03-06T08:00:00; 2017-03-06T20:00:00; 2017...   \n",
       "\n",
       "                                  arrival_datetime_1  \\\n",
       "0                                2017-05-30T11:58:00   \n",
       "1                                2017-03-29T18:53:00   \n",
       "2           2017-02-10T09:03:00; 2017-02-10T16:31:00   \n",
       "3           2017-05-10T14:45:00; 2017-05-11T12:55:00   \n",
       "4  2017-03-06T16:35:00; 2017-03-07T07:15:00; 2017...   \n",
       "\n",
       "                                departure_datetime_2  \\\n",
       "0                                2017-06-03T13:00:00   \n",
       "1                                                NaN   \n",
       "2           2017-02-13T08:47:00; 2017-02-13T11:40:00   \n",
       "3           2017-05-28T12:55:00; 2017-05-28T17:50:00   \n",
       "4  2017-03-09T06:00:00; 2017-03-09T16:50:00; 2017...   \n",
       "\n",
       "                                  arrival_datetime_2  \\\n",
       "0                                2017-06-03T14:36:00   \n",
       "1                                                NaN   \n",
       "2           2017-02-13T10:30:00; 2017-02-13T13:41:00   \n",
       "3           2017-05-28T16:05:00; 2017-05-28T19:11:00   \n",
       "4  2017-03-09T08:35:00; 2017-03-09T20:15:00; 2017...   \n",
       "\n",
       "                           itinerary_id  \n",
       "0  c53826cf-1fba-42a6-a765-941628e1901e  \n",
       "1  2e3afcd8-7d56-4b49-a71b-f85c23e1b807  \n",
       "2  619b0f7c-825f-47b1-a191-300862feff80  \n",
       "3  37a44686-8347-4c72-8690-c9432349f9a6  \n",
       "4  b84a4eca-fd5f-4794-afaa-e1d0e7231537  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Search Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1277062 entries, 0 to 1277061\n",
      "Data columns (total 25 columns):\n",
      "search_id               1277062 non-null object\n",
      "search_time             1277062 non-null object\n",
      "currency                1277062 non-null object\n",
      "destination             1277062 non-null object\n",
      "search_user_id          1277062 non-null object\n",
      "language                1277062 non-null object\n",
      "origin                  1277062 non-null object\n",
      "partner_id              1277062 non-null int64\n",
      "passengers              1277062 non-null int64\n",
      "pos                     1271955 non-null object\n",
      "session_id              1277062 non-null object\n",
      "user_agent              1268917 non-null object\n",
      "num_requests            1277062 non-null int64\n",
      "fare                    1277062 non-null float64\n",
      "supplier                1277062 non-null int64\n",
      "cabin_class             1277062 non-null object\n",
      "carrier_1               1277062 non-null object\n",
      "carrier_2               1042662 non-null object\n",
      "flight_num_1            1277062 non-null object\n",
      "flight_num_2            1042662 non-null object\n",
      "departure_datetime_1    1277062 non-null object\n",
      "arrival_datetime_1      1277062 non-null object\n",
      "departure_datetime_2    1042662 non-null object\n",
      "arrival_datetime_2      1042662 non-null object\n",
      "itinerary_id            103121 non-null object\n",
      "dtypes: float64(1), int64(4), object(20)\n",
      "memory usage: 243.6+ MB\n"
     ]
    }
   ],
   "source": [
    "search_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1277062, 25)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['search_id', 'search_time', 'currency', 'destination', 'search_user_id',\n",
       "       'language', 'origin', 'partner_id', 'passengers', 'pos', 'session_id',\n",
       "       'user_agent', 'num_requests', 'fare', 'supplier', 'cabin_class',\n",
       "       'carrier_1', 'carrier_2', 'flight_num_1', 'flight_num_2',\n",
       "       'departure_datetime_1', 'arrival_datetime_1', 'departure_datetime_2',\n",
       "       'arrival_datetime_2', 'itinerary_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_id</th>\n",
       "      <th>search_time</th>\n",
       "      <th>currency</th>\n",
       "      <th>destination</th>\n",
       "      <th>search_user_id</th>\n",
       "      <th>language</th>\n",
       "      <th>origin</th>\n",
       "      <th>partner_id</th>\n",
       "      <th>passengers</th>\n",
       "      <th>pos</th>\n",
       "      <th>...</th>\n",
       "      <th>cabin_class</th>\n",
       "      <th>carrier_1</th>\n",
       "      <th>carrier_2</th>\n",
       "      <th>flight_num_1</th>\n",
       "      <th>flight_num_2</th>\n",
       "      <th>departure_datetime_1</th>\n",
       "      <th>arrival_datetime_1</th>\n",
       "      <th>departure_datetime_2</th>\n",
       "      <th>arrival_datetime_2</th>\n",
       "      <th>itinerary_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02c6c2ad-325b-4155-bb03-89badc92ea84</td>\n",
       "      <td>2017-02-01 00:00:07</td>\n",
       "      <td>USD</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NBYNv9utORVjlf604rUgXL/eFz6Tmu2NyygDWTFsM5OOWH...</td>\n",
       "      <td>en</td>\n",
       "      <td>LAX</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA1088</td>\n",
       "      <td>AA1147</td>\n",
       "      <td>2017-04-07T09:50:00-07:00</td>\n",
       "      <td>2017-04-07T17:56:00-04:00</td>\n",
       "      <td>2017-04-16T21:30:00-04:00</td>\n",
       "      <td>2017-04-17T00:33:00-07:00</td>\n",
       "      <td>294f363b-86f0-4e67-abe9-05221dadb8b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0280e382-d24e-4138-bb20-8d236c0bb02f</td>\n",
       "      <td>2017-02-01 00:00:32</td>\n",
       "      <td>ISK</td>\n",
       "      <td>VCE</td>\n",
       "      <td>c2ea8bd4-40ff-4b8b-a42f-ada9b02ef963</td>\n",
       "      <td>en</td>\n",
       "      <td>REK</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>IS</td>\n",
       "      <td>...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>FI; IB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FI540; IB5120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-06-10T01:05:00; 2017-06-10T14:50:00</td>\n",
       "      <td>2017-06-10T06:20:00; 2017-06-10T16:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d9592a05-c850-4abd-9cf1-9fe8343d556c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c8903983-3eb9-4f0f-8f87-64b7e5dd0692</td>\n",
       "      <td>2017-02-01 00:00:39</td>\n",
       "      <td>USD</td>\n",
       "      <td>SJD</td>\n",
       "      <td>36195bda-ec40-4907-9428-c4fe11bd87fa</td>\n",
       "      <td>en</td>\n",
       "      <td>LAX</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA237</td>\n",
       "      <td>AA237</td>\n",
       "      <td>2017-05-30T08:35:00</td>\n",
       "      <td>2017-05-30T11:58:00</td>\n",
       "      <td>2017-06-03T13:00:00</td>\n",
       "      <td>2017-06-03T14:36:00</td>\n",
       "      <td>c53826cf-1fba-42a6-a765-941628e1901e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b1d666c8-d570-47ec-bc46-26ee5332620f</td>\n",
       "      <td>2017-02-01 00:00:48</td>\n",
       "      <td>USD</td>\n",
       "      <td>LHR</td>\n",
       "      <td>36ba8a8c-8c47-4dc6-bd70-0b3ae071c8cf</td>\n",
       "      <td>en</td>\n",
       "      <td>PHX</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>economy</td>\n",
       "      <td>DL; DL</td>\n",
       "      <td>DL; DL</td>\n",
       "      <td>DL5852; DL4414</td>\n",
       "      <td>DL11; DL1516</td>\n",
       "      <td>2017-05-10T13:13:00; 2017-05-10T18:30:00</td>\n",
       "      <td>2017-05-10T14:45:00; 2017-05-11T12:55:00</td>\n",
       "      <td>2017-05-28T12:55:00; 2017-05-28T17:50:00</td>\n",
       "      <td>2017-05-28T16:05:00; 2017-05-28T19:11:00</td>\n",
       "      <td>37a44686-8347-4c72-8690-c9432349f9a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>020521d7-ea85-49dd-97e2-1ae662f432a9</td>\n",
       "      <td>2017-02-01 00:00:48</td>\n",
       "      <td>ISK</td>\n",
       "      <td>BFS</td>\n",
       "      <td>cc24b343-7e53-48b4-9bdb-092a49381665</td>\n",
       "      <td>is</td>\n",
       "      <td>REK</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>IS</td>\n",
       "      <td>...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>FI; FR</td>\n",
       "      <td>FR; U2</td>\n",
       "      <td>FI470; FR1274</td>\n",
       "      <td>FR1138; U28507</td>\n",
       "      <td>2017-04-12T07:35:00; 2017-04-12T18:10:00</td>\n",
       "      <td>2017-04-12T11:35:00; 2017-04-12T19:35:00</td>\n",
       "      <td>2017-04-19T20:00:00; 2017-04-20T06:30:00</td>\n",
       "      <td>2017-04-19T21:20:00; 2017-04-20T08:45:00</td>\n",
       "      <td>52248983-0449-411f-9794-88c7bc098faa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              search_id          search_time currency  \\\n",
       "0  02c6c2ad-325b-4155-bb03-89badc92ea84  2017-02-01 00:00:07      USD   \n",
       "1  0280e382-d24e-4138-bb20-8d236c0bb02f  2017-02-01 00:00:32      ISK   \n",
       "2  c8903983-3eb9-4f0f-8f87-64b7e5dd0692  2017-02-01 00:00:39      USD   \n",
       "3  b1d666c8-d570-47ec-bc46-26ee5332620f  2017-02-01 00:00:48      USD   \n",
       "4  020521d7-ea85-49dd-97e2-1ae662f432a9  2017-02-01 00:00:48      ISK   \n",
       "\n",
       "  destination                                     search_user_id language  \\\n",
       "0         MIA  NBYNv9utORVjlf604rUgXL/eFz6Tmu2NyygDWTFsM5OOWH...       en   \n",
       "1         VCE               c2ea8bd4-40ff-4b8b-a42f-ada9b02ef963       en   \n",
       "2         SJD               36195bda-ec40-4907-9428-c4fe11bd87fa       en   \n",
       "3         LHR               36ba8a8c-8c47-4dc6-bd70-0b3ae071c8cf       en   \n",
       "4         BFS               cc24b343-7e53-48b4-9bdb-092a49381665       is   \n",
       "\n",
       "  origin  partner_id  passengers pos                  ...                   \\\n",
       "0    LAX         294           1  US                  ...                    \n",
       "1    REK          58           1  IS                  ...                    \n",
       "2    LAX          91           1  US                  ...                    \n",
       "3    PHX          91           2  US                  ...                    \n",
       "4    REK          58           2  IS                  ...                    \n",
       "\n",
       "  cabin_class carrier_1  carrier_2    flight_num_1    flight_num_2  \\\n",
       "0     economy        AA         AA          AA1088          AA1147   \n",
       "1     Economy    FI; IB        NaN   FI540; IB5120             NaN   \n",
       "2     economy        AA         AA           AA237           AA237   \n",
       "3     economy    DL; DL     DL; DL  DL5852; DL4414    DL11; DL1516   \n",
       "4     Economy    FI; FR     FR; U2   FI470; FR1274  FR1138; U28507   \n",
       "\n",
       "                       departure_datetime_1  \\\n",
       "0                 2017-04-07T09:50:00-07:00   \n",
       "1  2017-06-10T01:05:00; 2017-06-10T14:50:00   \n",
       "2                       2017-05-30T08:35:00   \n",
       "3  2017-05-10T13:13:00; 2017-05-10T18:30:00   \n",
       "4  2017-04-12T07:35:00; 2017-04-12T18:10:00   \n",
       "\n",
       "                         arrival_datetime_1  \\\n",
       "0                 2017-04-07T17:56:00-04:00   \n",
       "1  2017-06-10T06:20:00; 2017-06-10T16:40:00   \n",
       "2                       2017-05-30T11:58:00   \n",
       "3  2017-05-10T14:45:00; 2017-05-11T12:55:00   \n",
       "4  2017-04-12T11:35:00; 2017-04-12T19:35:00   \n",
       "\n",
       "                       departure_datetime_2  \\\n",
       "0                 2017-04-16T21:30:00-04:00   \n",
       "1                                       NaN   \n",
       "2                       2017-06-03T13:00:00   \n",
       "3  2017-05-28T12:55:00; 2017-05-28T17:50:00   \n",
       "4  2017-04-19T20:00:00; 2017-04-20T06:30:00   \n",
       "\n",
       "                         arrival_datetime_2  \\\n",
       "0                 2017-04-17T00:33:00-07:00   \n",
       "1                                       NaN   \n",
       "2                       2017-06-03T14:36:00   \n",
       "3  2017-05-28T16:05:00; 2017-05-28T19:11:00   \n",
       "4  2017-04-19T21:20:00; 2017-04-20T08:45:00   \n",
       "\n",
       "                           itinerary_id  \n",
       "0  294f363b-86f0-4e67-abe9-05221dadb8b8  \n",
       "1  d9592a05-c850-4abd-9cf1-9fe8343d556c  \n",
       "2  c53826cf-1fba-42a6-a765-941628e1901e  \n",
       "3  37a44686-8347-4c72-8690-c9432349f9a6  \n",
       "4  52248983-0449-411f-9794-88c7bc098faa  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `airport_data` contains information about various airports (listed as `destination` or `origin` in the other data files), `booking_data` contains information about successful bookings, and `search_data` contains information about searches. It's also apparent that many of the entries in `booking_data` are connected to the entries in `search_data` by their `itinerary_id` column. I'll use this information in the feature engineering stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4  Columns in common\n",
    "It seems like `booking_data` and `search_data` have most of their columns in common. So I'll check the symmetric difference of the sets (`booking_data` $\\bigoplus$ `search_data`) to see what items I'll have to work on independently. For the rest, I'll simply loop over both `search_data` and `booking_data`.\n",
    "\n",
    "#### Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'search_user_id', 'search_time', 'booking_user_id', 'booking_time', 'booking_id', 'search_id'}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pprint\n",
    "set(booking_data.columns) ^ set(search_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In common\n",
    "And here are the columns that the datasets have in common, which I'll start cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'departure_datetime_2', 'arrival_datetime_1', 'user_agent', 'fare', 'itinerary_id', 'carrier_1', 'cabin_class', 'flight_num_1', 'destination', 'session_id', 'supplier', 'carrier_2', 'currency', 'partner_id', 'departure_datetime_1', 'pos', 'origin', 'arrival_datetime_2', 'passengers', 'language', 'num_requests', 'flight_num_2'}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(booking_data.columns) & set(search_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data preparation\n",
    "## 3.1 Overview of features\n",
    "Different columns will need to be cleaned up in different ways. I'll make some predictions about which columns to keep, which to modify, and which to drop. I'm going to make my life easier by not trying to calculate the total flight time, which would require de-localizing the various departure/arrival times. Instead I'll only concern myself with features generated from the first departure time. Trying to mix together both one-way and return flights is a bit of a headache, because all one-way flights will have missing values for the return column. In the table below, \"departure\" means the first flight the passenger boards during their trip.\n",
    "\n",
    "### 3.1.1 Existing features\n",
    "\n",
    "\n",
    "| column               | data type    | comments                | fate    |\n",
    "| ---------------------|:------------:|:-----------------------:|--------:|\n",
    "| departure_datetime_1 | datetime     | extract features        | drop             |\n",
    "| departure_datetime_2 | datetime     | extract features        | drop             |\n",
    "| arrival_datetime_1   | datetime     | extract features        | drop             |\n",
    "| arrival_datetime_2   | datetime     | extract features        | drop             |\n",
    "| cabin_class          | categorical  | convert to \"buckets\"    | dummy variables  |\n",
    "| carrier_1 *            | categorical  | lots of carriers        | drop            |\n",
    "| carrier_2 *            | categorical  | lots of carriers        | drop            |\n",
    "| currency *             | categorical  | use for USD conversion  | drop            |\n",
    "| origin *               | categorical  | lots of origins         | drop            |\n",
    "| destination *          | categorical  | lots of destinations    | drop            |\n",
    "| fare                 | discrete int | dependent variable      | convert to USD   |\n",
    "| flght_num_1          | categorical  | ID                      | drop             |\n",
    "| flight_num_2         | categorical  | ID                      | drop             |\n",
    "| itinerary_id         | categorical  | useful in engineering phase | drop         |\n",
    "| language             | categorical  | almost all searches are in \"en\" | drop |\n",
    "| num_requests         | discrete int |                         | min-max scaled   |\n",
    "| partner_id *           | categorical  | lots of partners        | drop            |\n",
    "| passengers           | discrete int |                         | min-max scaled   |\n",
    "| pos *                  | categorical  | lots of points-of-sale  | drop            |\n",
    "| session_id           | categorical  | ID data. Not useful     | drop             |\n",
    "| supplier *             | categorical  | lots of suppliers       | drop            |\n",
    "| user_agent †          | categorical  | requires lots of feat. engineering | drop  |\n",
    "|                      |              |                         |                  |\n",
    "| booking_id           | categorical  | ID. useful in eng phase | drop             |\n",
    "| booking_time         | datetime     | convert to \"buckets\"    | dummy variables  |\n",
    "| booking_user_id      | categorical  |                         | drop             |\n",
    "| search_id            | categorical  |                         | drop             |\n",
    "| search_time          | datetime     | convert to \"buckets\"    | dummy variables  |\n",
    "| search_user_id       | categorical  |                         | drop             |\n",
    "\n",
    "\\* Ideally, these categorical variables would be preserved as dummy variables. However, these variables take on a lot of different values, which means the machine algorithms I'll use later on will be a lot slower. So I'm avoiding that pain by simply dropping them.\n",
    "\n",
    "† I could extract information from this feature, but I don't think it'll be worth the effort. I could return to this if my model's accuracy is not high enough.\n",
    "\n",
    "\n",
    "### 3.1.3 Features to be created\n",
    "\n",
    "| new feature (column) | data type      | comments                                 |\n",
    "| ---------------------|:--------------:|-----------------------------------------:|\n",
    "| distance_traveled    | continuous int | haversine distance                       |\n",
    "| one_way              | binary         | was the flight one-way?                  |\n",
    "| was_airfare_booked   | binary         | dependent variable for task (2)         |\n",
    "| booking_depart_diff  | datetime       | time between booking and departure       |\n",
    "| search_depart_diff   | datetime       | time between search and departure        |\n",
    "| time_till_xmas * | datetime       | time between departure and next holiday  |\n",
    "| time_from_xmas * | datetime       | time between departure and last holiday  |\n",
    "| time_till_ny * | datetime       | time between departure and next holiday  |\n",
    "| time_from_ny * | datetime       | time between departure and last holiday  |\n",
    "| time_till_tgiving * | datetime       | time between departure and next holiday  |\n",
    "| time_from_tgiving * | datetime       | time between departure and last holiday  |\n",
    "| time_till_cny * | datetime       | time between departure and next holiday  |\n",
    "| time_from_cny * | datetime       | time between departure and last holiday  |\n",
    "| departure_weekday          | categorical    | was this a weekday - will become a dummy variable |\n",
    "| departure_day_of_week          | categorical    | the day of the week - will become a dummy variable |\n",
    "| departure_week_of_year          | categorical    | the week of the year - will become a dummy variable |\n",
    "\n",
    "\\* popular holidays = Christmas, Thanksgiving, New Years, Chinese New Year. I could endlessly engineer date features and even do a little research into other Holidays (Eid, Diwali, Golden Week, etc.) but that might take a lot of time. So I'm limiting my \"holidays\" to just these three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Existing features\n",
    "### 3.2.1 Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pos', 1350), ('user_agent', 3369), ('carrier_2', 3476), ('flight_num_2', 3476), ('departure_datetime_2', 3476), ('arrival_datetime_2', 3476), ('pos', 5107), ('user_agent', 8145), ('carrier_2', 234400), ('flight_num_2', 234400), ('departure_datetime_2', 234400), ('arrival_datetime_2', 234400), ('itinerary_id', 1173941)]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List column names with missing values for \"booking\" and \"search\" data.\n",
    "booking_ = dict(booking_data.isnull().sum())\n",
    "search_ = dict(search_data.isnull().sum())\n",
    "[(x, booking_[x]) for x in booking_ if booking_[x] > 0] + \\\n",
    "[(x, search_[x]) for x in search_ if search_[x] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, these are all columns that are going to be dropped, so they don't need to be considered anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 57, 'longitude': 57, 'altitude': 133, 'timezone': 63, 'dst': 119, 'aggregate_code': 62}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List column names with missing values for \"airport\" data.\n",
    "airport_ = dict(airport_data.isnull().sum())\n",
    "dict([(x, airport_[x]) for x in airport_ if airport_[x] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude and longitude are the only columns from this database that I'm going to use that also have missing values. Luckily, information about the city and country exists for every entry. I can use this information to reconstruct the missing coordinate data. This will match cities, not airports, but should be close enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the rows with missing coordinate data into a temporary separate dataframe\n",
    "# There are 57 missing values.\n",
    "airport_data_1, airport_data_2 = airport_data.sort_values(by=['longitude'])[:-57], \\\n",
    "     airport_data.sort_values(by=['longitude'])[-57:]\n",
    "\n",
    "# Define a function to fetch geolocations\n",
    "def handle_geo(loc, pos):\n",
    "    \"\"\"\n",
    "    This API does not always return a value, so retry several times.\n",
    "    \"\"\"\n",
    "    attempts = 0\n",
    "    while attempts < 20:\n",
    "        try:\n",
    "            return geocoder.google(loc).latlng[pos]\n",
    "        except:\n",
    "            attempts += 1\n",
    "    return None\n",
    "\n",
    "# Generate temporary column\n",
    "airport_data_2['location'] = airport_data_2['city'] + ', ' + airport_data_2['country']\n",
    "\n",
    "# Fetch coordinate data from temporary column\n",
    "airport_data_2['latitude'] = airport_data_2['location']. \\\n",
    "        apply(lambda x: handle_geo(x, 0))\n",
    "airport_data_2['longitude'] = airport_data_2['location']. \\\n",
    "        apply(lambda x: handle_geo(x, 1))\n",
    "\n",
    "# Drop temporary column\n",
    "airport_data_2 = airport_data_2.drop(columns=['location'])\n",
    "\n",
    "# Recombine datasets\n",
    "airport_data = pd.concat([airport_data_1, airport_data_2])\n",
    "\n",
    "# Drop any rows in case null values crept through\n",
    "airport_data = airport_data.dropna(subset=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values from airport_data\n",
    "airport_data = airport_data.dropna(subset=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Convert to correct format\n",
    "Most of the date data is not in date format. This is because the date columns represent the departure/arrival times for all flights on an itinerary, not just one. I decided earlier on to only concern myself with only three date variables: `booking_time`, `search_time`, and the departure time of the very first flight: `departure_datetime_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert booking_time and search_time\n",
    "booking_data['booking_time'] = pd.to_datetime(booking_data['booking_time'])\n",
    "search_data['search_time'] = pd.to_datetime(search_data['search_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 43)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first departure time. Convert to date. Coerce errors to NaT\n",
    "for db in [booking_data, search_data]:\n",
    "    db['departure_datetime_1'] = pd.to_datetime(db['departure_datetime_1'] \\\n",
    "            .apply(lambda x: str(x).split(';')[0]), errors='coerce')\n",
    "    \n",
    "# Confirm that not too many null values were created:\n",
    "dict(booking_data.isnull().sum())['departure_datetime_1'], \\\n",
    "dict(search_data.isnull().sum())['departure_datetime_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing data in departure_datetime_1\n",
    "booking_data = booking_data.dropna(subset=['departure_datetime_1'])\n",
    "search_data = search_data.dropna(subset=['departure_datetime_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Bucketize cabin variable\n",
    "I'll start off by handling the various entries in the `cabin` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premium_economy', 'Premium Economy', 'COACH', 'first', 'mixed', 'business', 'First', 'Business', 'First Class', 'Economy', 'economy'}"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(booking_data.cabin_class.unique()) & set(search_data.cabin_class.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [this website](https://www.cheapair.com/help/flights/what-are-the-different-classes-of-service-on-a-plane/), the class of an airline ticket can be divided into four buckets of increasing price/comfort, so I'll modify the data to reflect that (I had to guess about \"mixed\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin_buckets(row):\n",
    "    if row in ['economy', 'Economy', 'COACH', 'mixed']:\n",
    "        return 'economy'\n",
    "    if row in ['premium_economy', 'Premium Economy']:\n",
    "        return 'premium_economy'\n",
    "    if row in ['business', 'Business']:\n",
    "        return 'business'\n",
    "    if row in ['First', 'First Class']:\n",
    "        return 'first'\n",
    "\n",
    "for db in [booking_data, search_data]:\n",
    "    db['cabin_class'] = db['cabin_class'].apply(lambda x: cabin_buckets(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Convert fare\n",
    "The fare information (which is the dependent variable) seems to be in a variety of different currencies. This will cause problems, so let's convert it all to USD. I'll make use of a third-party package to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MYR', 'NZD', 'AUD', 'ZAR', 'HUF', 'CHF', 'CNY', 'PHP', 'AED', 'EUR', 'THB', 'CZK', 'MXN', 'JPY', 'HKD', 'KRW', 'GBP', 'NOK', 'SGD', 'USD', 'DKK', 'CAD', 'ISK', 'SEK'}"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(booking_data.currency.unique()) & set(search_data.currency.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 917)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import currencyconverter\n",
    "\n",
    "from currency_converter import CurrencyConverter\n",
    "c = CurrencyConverter()\n",
    "\n",
    "# A wrapper function to handle errors.\n",
    "def convert_wrap(fare, from_, to_):\n",
    "    try:\n",
    "        return c.convert(fare, from_, to_)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# It's annoying to transform this third-party module into something that can be\n",
    "# easily vectorized, so I'll cheat and create a new column, called fare_map,\n",
    "# which will tell us what to multiply the \"fare\" column by in order to get\n",
    "# the fare in USD. This is trading I/O and CPU time for RAM -- a trade I'm\n",
    "# happy to make.\n",
    "\n",
    "currency_mapping = {}\n",
    "for currency in list(booking_data.currency.unique()) + list(search_data.currency.unique()):\n",
    "    currency_mapping[currency] = convert_wrap(1, currency, 'USD')\n",
    "    \n",
    "for db in [booking_data, search_data]:\n",
    "    db['fare_map'] = db['currency'].apply(lambda x: currency_mapping[x])\n",
    "\n",
    "for db in [booking_data, search_data]:\n",
    "    db['fare'] = db['fare'] * db['fare_map']\n",
    "    db = db.drop(columns=['fare_map'])\n",
    "    \n",
    "# Confirm that not too many null values were created:\n",
    "dict(booking_data.isnull().sum())['fare'], \\\n",
    "dict(search_data.isnull().sum())['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing data in fare\n",
    "booking_data = booking_data.dropna(subset=['fare'])\n",
    "search_data = search_data.dropna(subset=['fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Engineer new features\n",
    "### 3.3.1 Distance traveled\n",
    "Now it's time to start engineering features. Let's figure out how far the plane traveled by using the Haversine distance between the origin and destination airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between the airport code and the coordinates.\n",
    "airport_lat_coordinates = pd.Series(airport_data.latitude.values,index=airport_data.iata_code).to_dict()\n",
    "airport_lon_coordinates = pd.Series(airport_data.longitude.values,index=airport_data.iata_code).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's insert this information into `search_data` and `booking_data` for each flight. I'll make some temporary columns and then compute distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Define some helper functions.\n",
    "def map_lat_coords(x):\n",
    "    try:\n",
    "        return airport_lat_coordinates[x]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def map_lon_coords(x):\n",
    "    try:\n",
    "        return airport_lon_coordinates[x]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Create some temporary columns with coordinate data.\n",
    "for db in [booking_data, search_data]:\n",
    "    db['origin_lat'] = db['origin'].apply(map_lat_coords)\n",
    "    db['origin_lon'] = db['origin'].apply(map_lon_coords)\n",
    "    db['destination_lat'] = db['destination'].apply(map_lat_coords)\n",
    "    db['destination_lon'] = db['destination'].apply(map_lon_coords)\n",
    "    \n",
    "# Define a Haversine distance function.\n",
    "# Surprisingly, numpy does not have this!\n",
    "from numpy import radians, cos, sin, arcsin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great distance between two points \n",
    "    on the earth from their longitude and latitude.\n",
    "    Returns the distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians. \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine distance formula.\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * arcsin(sqrt(a))\n",
    "    r = 6371 # Radius of earth in kilometers. Miles = 3956.\n",
    "    return c * r\n",
    "\n",
    "# Use the columns to calculate the distance traveled and drop temporary columns.\n",
    "for db in [booking_data, search_data]:\n",
    "    db['distance_traveled'] = haversine(db['origin_lon'], \\\n",
    "            db['origin_lat'], db['destination_lon'], db['destination_lat'])\n",
    "    \n",
    "search_data = search_data.drop(columns=['origin_lon', 'origin_lat', \\\n",
    "        'destination_lon', 'destination_lat'])\n",
    "booking_data = booking_data.drop(columns=['origin_lon', 'origin_lat', \\\n",
    "        'destination_lon', 'destination_lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 4)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that there are not too many missing entries\n",
    "# This is dependent upon the Geopy API getting coordinates\n",
    "# for every city.\n",
    "dict(search_data.isnull().sum())['distance_traveled'], \\\n",
    "dict(booking_data.isnull().sum())['distance_traveled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_data = booking_data.dropna(subset=['distance_traveled'])\n",
    "search_data = search_data.dropna(subset=['distance_traveled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Was the airfare booked?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal (2) was to predict which airfares are booked. Because there's no `was_airfare_booked` column in the dataset, I'll have to engineer this dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the entries into a dict for faster lookup time: dict = O(1), list = O(n).\n",
    "booked_flight = {}\n",
    "for flight in booking_data['itinerary_id']:\n",
    "    booked_flight[flight] = 1\n",
    "\n",
    "# Function to check whether an entry is in the dict. If not, return 0.\n",
    "def was_booked(id):\n",
    "    return booked_flight.get(id, 0)\n",
    "\n",
    "search_data['was_airfare_booked'] = search_data['itinerary_id']. \\\n",
    "        apply(lambda x: was_booked(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Was the flight one-way?\n",
    "If a row has a null value for `flight_num_2`, then it is safe to assume that there was no return flight, and therefore the flight was one-way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_way(x):\n",
    "    if pd.notnull(x):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "for db in [booking_data, search_data]:\n",
    "    db['one_way_flight'] = db['flight_num_2'].apply(lambda x: one_way(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Depart diff\n",
    "I imagine that flights which are booked earlier will be cheaper. Searches that happen later might correspond to more likely bookings (desperation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data['depart_diff'] = \\\n",
    "        search_data['departure_datetime_1'] - search_data['search_time']\n",
    "booking_data['depart_diff'] = \\\n",
    "        booking_data['departure_datetime_1'] - booking_data['booking_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to know the times between the departures and various holidays. This variable is likely to be non-linear for `search_data`, because flights with very small or negative depart_diffs probably weren't booked, as well as searches from very far out. Let's see if there's a non-linear relationship: **[plot this]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 Various date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [booking_data, search_data]:\n",
    "    df['departure_dayofweek'] = df['departure_datetime_1'].dt.dayofweek\n",
    "    df['departure_weekday'] = df['departure_datetime_1'].dt.weekday\n",
    "    df['departure_weekofyear'] = df['departure_datetime_1'].dt.weekofyear\n",
    "    df['departure_dayofyear'] = df['departure_datetime_1'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOLIDAYS NOT INCLUDED\n",
    "\n",
    "# import datetime\n",
    "# def time_till_holiday(time, holiday):\n",
    "#     # Select the smallest non-negative time.\n",
    "#     possible_diffs = [day - time for day in holiday]\n",
    "#     return min([diff > datetime.timedelta(0) for diff in possible_diffs])\n",
    "\n",
    "# import datetime\n",
    "# def time_from_holiday(time, holiday):\n",
    "#     # Select the smallest non-negative time.\n",
    "#     possible_diffs = [day - time for day in holiday]\n",
    "#     return min([diff > datetime.timedelta(0) for diff in possible_diffs])\n",
    "\n",
    "# xmas_times = [pd.Timestamp('2016-25-12'), pd.Timestamp('2017-25-12'), pd.Timestamp('2018-25-12')]\n",
    "# ny_times = [pd.Timestamp('2016-01-01'), pd.Timestamp('2017-01-01'), pd.Timestamp('2018-01-01')]\n",
    "# tgiving_times = [pd.Timestamp('2016-11-24'), pd.Timestamp('2017-11-23'), pd.Timestamp('2018-11-22')]\n",
    "# cny_times = [pd.Timestamp('2016-02-08'), pd.Timestamp('2017-01-28'), pd.Timestamp('2018-02-16')]\n",
    "\n",
    "\n",
    "# for df in [booking_data, search_data]:\n",
    "#     df['departure_time_till_xmas'] = df['departure_datetime_1']. \\\n",
    "#             apply(lambda x: time_till_holiday(x, xmas_times))\n",
    "#     df['departure_time_from_xmas'] = df['departure_datetime_1']\n",
    "#     df['departure_time_till_ny'] = df['departure_datetime_1']\n",
    "#     df['departure_time_from_ny'] = df['departure_datetime_1']\n",
    "#     df['departure_time_till_tgiving'] = df['departure_datetime_1']\n",
    "#     df['departure_time_from_tgiving'] = df['departure_datetime_1']\n",
    "#     df['departure_time_till_cny'] = df['departure_datetime_1']\n",
    "#     df['departure_time_from_cny'] = df['departure_datetime_1']\n",
    "\n",
    "# booking_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Convert variables\n",
    "Let's drop the columns we don't need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16799 entries, 0 to 16853\n",
      "Data columns (total 33 columns):\n",
      "booking_id              16799 non-null object\n",
      "booking_time            16799 non-null datetime64[ns]\n",
      "currency                16799 non-null object\n",
      "destination             16799 non-null object\n",
      "booking_user_id         16799 non-null object\n",
      "language                16799 non-null object\n",
      "origin                  16799 non-null object\n",
      "partner_id              16799 non-null int64\n",
      "passengers              16799 non-null int64\n",
      "pos                     15461 non-null object\n",
      "session_id              16799 non-null object\n",
      "user_agent              13457 non-null object\n",
      "num_requests            16799 non-null int64\n",
      "fare                    16799 non-null float64\n",
      "supplier                16799 non-null int64\n",
      "cabin_class             16755 non-null object\n",
      "carrier_1               16799 non-null object\n",
      "carrier_2               13349 non-null object\n",
      "flight_num_1            16799 non-null object\n",
      "flight_num_2            13349 non-null object\n",
      "departure_datetime_1    16799 non-null datetime64[ns]\n",
      "arrival_datetime_1      16799 non-null object\n",
      "departure_datetime_2    13349 non-null object\n",
      "arrival_datetime_2      13349 non-null object\n",
      "itinerary_id            16799 non-null object\n",
      "fare_map                16799 non-null float64\n",
      "distance_traveled       16799 non-null float64\n",
      "one_way_flight          16799 non-null int64\n",
      "depart_diff             16799 non-null timedelta64[ns]\n",
      "departure_dayofweek     16799 non-null int64\n",
      "departure_weekday       16799 non-null int64\n",
      "departure_weekofyear    16799 non-null int64\n",
      "departure_dayofyear     16799 non-null int64\n",
      "dtypes: datetime64[ns](2), float64(3), int64(9), object(18), timedelta64[ns](1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "booking_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "booking_data = booking_data.drop(columns=['booking_id', 'booking_user_id', \\\n",
    "            'pos', 'user_agent', 'num_requests', 'supplier', 'flight_num_1', \\\n",
    "            'flight_num_2', 'currency', 'carrier_1', 'carrier_2', 'partner_id', \\\n",
    "            'arrival_datetime_1', 'arrival_datetime_2', 'departure_datetime_2', \\\n",
    "            'origin', 'destination', 'fare_map', 'itinerary_id', 'session_id', \\\n",
    "            'language', 'booking_time', 'departure_datetime_1'])\n",
    "\n",
    "search_data = search_data.drop(columns=['search_id', 'search_user_id', \\\n",
    "            'pos', 'user_agent', 'num_requests', 'supplier', 'flight_num_1', \\\n",
    "            'flight_num_2', 'currency', 'carrier_1', 'carrier_2', 'partner_id', \\\n",
    "            'arrival_datetime_1', 'arrival_datetime_2', 'departure_datetime_2', \\\n",
    "            'origin', 'destination', 'fare_map', 'itinerary_id', 'session_id', \\\n",
    "            'language', 'search_time', 'departure_datetime_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Convert categorical data to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for db in [booking_data, search_data]:\n",
    "for variable in ['cabin_class', 'one_way_flight', 'departure_dayofweek', \\\n",
    "                 'departure_weekday', 'departure_weekofyear']:\n",
    "    class_dummy = pd.get_dummies(search_data[variable], prefix=variable)\n",
    "    search_data = search_data.merge(class_dummy, left_index=True, right_index=True)\n",
    "    search_data = search_data.drop(columns=variable)\n",
    "    \n",
    "for variable in ['cabin_class', 'one_way_flight', 'departure_dayofweek', \\\n",
    "                 'departure_weekday', 'departure_weekofyear']:\n",
    "    class_dummy = pd.get_dummies(booking_data[variable], prefix=variable)\n",
    "    booking_data = booking_data.merge(class_dummy, left_index=True, right_index=True)\n",
    "    booking_data = booking_data.drop(columns=variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Convert timedelta to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_data['depart_diff'] = booking_data['depart_diff'].astype(int)\n",
    "search_data['depart_diff'] = search_data['depart_diff'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengers</th>\n",
       "      <th>fare</th>\n",
       "      <th>distance_traveled</th>\n",
       "      <th>depart_diff</th>\n",
       "      <th>departure_dayofyear</th>\n",
       "      <th>cabin_class_business_x</th>\n",
       "      <th>cabin_class_economy_x</th>\n",
       "      <th>cabin_class_first_x</th>\n",
       "      <th>cabin_class_premium_economy_x</th>\n",
       "      <th>one_way_flight_0_x</th>\n",
       "      <th>...</th>\n",
       "      <th>departure_weekofyear_43_y</th>\n",
       "      <th>departure_weekofyear_44_y</th>\n",
       "      <th>departure_weekofyear_45_y</th>\n",
       "      <th>departure_weekofyear_46_y</th>\n",
       "      <th>departure_weekofyear_47_y</th>\n",
       "      <th>departure_weekofyear_48_y</th>\n",
       "      <th>departure_weekofyear_49_y</th>\n",
       "      <th>departure_weekofyear_50_y</th>\n",
       "      <th>departure_weekofyear_51_y</th>\n",
       "      <th>departure_weekofyear_52_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>286.7900</td>\n",
       "      <td>1468.102596</td>\n",
       "      <td>10226054000000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>192.2000</td>\n",
       "      <td>3204.066376</td>\n",
       "      <td>4898037000000000</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>615.6000</td>\n",
       "      <td>2655.453559</td>\n",
       "      <td>805856000000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>507.4600</td>\n",
       "      <td>8464.632796</td>\n",
       "      <td>8514708000000000</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>888.8600</td>\n",
       "      <td>8615.468303</td>\n",
       "      <td>2879915000000000</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>352.6000</td>\n",
       "      <td>834.965181</td>\n",
       "      <td>9869006000000000</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>395.6400</td>\n",
       "      <td>1530.956220</td>\n",
       "      <td>1976753000000000</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>187.4300</td>\n",
       "      <td>1475.127551</td>\n",
       "      <td>1234710000000000</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>376.6000</td>\n",
       "      <td>1669.789075</td>\n",
       "      <td>4424249000000000</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>190.9656</td>\n",
       "      <td>1105.264012</td>\n",
       "      <td>8113927000000000</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengers      fare  distance_traveled        depart_diff  \\\n",
       "0           1  286.7900        1468.102596  10226054000000000   \n",
       "1           1  192.2000        3204.066376   4898037000000000   \n",
       "2           1  615.6000        2655.453559    805856000000000   \n",
       "3           2  507.4600        8464.632796   8514708000000000   \n",
       "4           1  888.8600        8615.468303   2879915000000000   \n",
       "5           3  352.6000         834.965181   9869006000000000   \n",
       "6           1  395.6400        1530.956220   1976753000000000   \n",
       "7           1  187.4300        1475.127551   1234710000000000   \n",
       "8           3  376.6000        1669.789075   4424249000000000   \n",
       "9           2  190.9656        1105.264012   8113927000000000   \n",
       "\n",
       "   departure_dayofyear  cabin_class_business_x  cabin_class_economy_x  \\\n",
       "0                  150                       0                      1   \n",
       "1                   88                       0                      1   \n",
       "2                   41                       0                      1   \n",
       "3                  130                       0                      1   \n",
       "4                   65                       0                      1   \n",
       "5                  146                       0                      1   \n",
       "6                   54                       0                      1   \n",
       "7                   46                       0                      1   \n",
       "8                   83                       0                      1   \n",
       "9                  125                       0                      1   \n",
       "\n",
       "   cabin_class_first_x  cabin_class_premium_economy_x  one_way_flight_0_x  \\\n",
       "0                    0                              0                   1   \n",
       "1                    0                              0                   0   \n",
       "2                    0                              0                   1   \n",
       "3                    0                              0                   1   \n",
       "4                    0                              0                   1   \n",
       "5                    0                              0                   1   \n",
       "6                    0                              0                   1   \n",
       "7                    0                              0                   1   \n",
       "8                    0                              0                   1   \n",
       "9                    0                              0                   1   \n",
       "\n",
       "             ...              departure_weekofyear_43_y  \\\n",
       "0            ...                                      0   \n",
       "1            ...                                      0   \n",
       "2            ...                                      0   \n",
       "3            ...                                      0   \n",
       "4            ...                                      0   \n",
       "5            ...                                      0   \n",
       "6            ...                                      0   \n",
       "7            ...                                      0   \n",
       "8            ...                                      0   \n",
       "9            ...                                      0   \n",
       "\n",
       "   departure_weekofyear_44_y  departure_weekofyear_45_y  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   departure_weekofyear_46_y  departure_weekofyear_47_y  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   departure_weekofyear_48_y  departure_weekofyear_49_y  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   departure_weekofyear_50_y  departure_weekofyear_51_y  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   departure_weekofyear_52_y  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "5                          0  \n",
       "6                          0  \n",
       "7                          0  \n",
       "8                          0  \n",
       "9                          0  \n",
       "\n",
       "[10 rows x 145 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Scale numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to scale passengers.\n",
    "for variable in ['fare', 'distance_traveled', 'depart_diff']:\n",
    "    scaler = StandardScaler()\n",
    "    booking_data[variable] = scaler.fit_transform(booking_data[[variable]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Future directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['search_id', 'search_time', 'currency', 'destination', 'search_user_id',\n",
       "        'language', 'origin', 'partner_id', 'passengers', 'pos', 'session_id',\n",
       "        'user_agent', 'num_requests', 'fare', 'supplier', 'cabin_class',\n",
       "        'carrier_1', 'carrier_2', 'flight_num_1', 'flight_num_2',\n",
       "        'departure_datetime_1', 'arrival_datetime_1', 'departure_datetime_2',\n",
       "        'arrival_datetime_2', 'itinerary_id', 'fare_map', 'distance_traveled',\n",
       "        'was_airfare_booked'],\n",
       "       dtype='object'),\n",
       " Index(['booking_id', 'booking_time', 'currency', 'destination',\n",
       "        'booking_user_id', 'language', 'origin', 'partner_id', 'passengers',\n",
       "        'pos', 'session_id', 'user_agent', 'num_requests', 'fare', 'supplier',\n",
       "        'cabin_class', 'carrier_1', 'carrier_2', 'flight_num_1', 'flight_num_2',\n",
       "        'departure_datetime_1', 'arrival_datetime_1', 'departure_datetime_2',\n",
       "        'arrival_datetime_2', 'itinerary_id', 'fare_map', 'distance_traveled'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data.columns, booking_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"labels ['booking_id' 'booking_user_id' 'partner_id'] not contained in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-931920c77e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbooking_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbooking_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'booking_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'booking_user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'partner_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msearch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'search_user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'partner_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbooking_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3692\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3694\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3138\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4387\u001b[0;31m                     'labels %s not contained in axis' % labels[mask])\n\u001b[0m\u001b[1;32m   4388\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"labels ['booking_id' 'booking_user_id' 'partner_id'] not contained in axis\""
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "booking_data = booking_data.drop(columns=['booking_id', 'booking_user_id', 'partner_id'])\n",
    "\n",
    "search_data = search_data.drop(columns=['search_id', 'search_user_id', 'partner_id'])\n",
    "\n",
    "for db in [booking_data, search_data]:\n",
    "    db = db.drop(columns=[\\\n",
    "                         'pos', 'user_agent', 'num_requests', 'supplier', 'flight_num_1', \\\n",
    "        'flight_num_2', 'currency', 'carrier_1', 'carrier_2'\n",
    "                         ])\n",
    "    \n",
    "search_data.columns, booking_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for ML Algorithms\n",
    "Now I need to convert all of the categorical variables into numerical variables. These \"dummy variables\" add extra compute time, so to make things simple, I've dropped two variables that have a lot of different members: `currency` and `carrier` even though they might be relevant for predicting the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the other features require modification. It's not fair to compare the cost of a flight with 5 people to a flight with only 1, so I'm going to create a `fare_per_passenger` column that divides `fare` by `passengers` and drop the `fare` column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
