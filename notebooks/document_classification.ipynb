{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification\n",
    "I'm interested in the task of _document classification_. In this notebook I try out several different techniques for document classification using the [IMDB Large Movie Review dataset](https://ai.stanford.edu/~amaas/data/sentiment/). Each row in the dataset consists of a written movie review along with the rating associated with the review (1 - 10). A positive review is defined as a review > 5. Anything lower than 5 is a negative review. I've reformulated this task as _sentiment classification_ by creating positive/negative ratings for each movie.\n",
    "\n",
    "After the normal data downloading and cleaning phase I experiment with a few different strategies:\n",
    "- V1: learning an embedding layer\n",
    "- V2: training glove embeddings on the dataset.\n",
    "- V3a: using pretrained embeddings (???)\n",
    "- V3b: using pretrained embeddings (Google universal embeddings)\n",
    "- V4:  more complicated deep learning architecture: embed sentences and documents, use CNN over documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  1.14.0\n",
      "Eager mode:  False\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeledBow.feat \u001b[1m\u001b[34mpos\u001b[m\u001b[m             unsupBow.feat   urls_pos.txt\n",
      "\u001b[1m\u001b[34mneg\u001b[m\u001b[m             \u001b[1m\u001b[34munsup\u001b[m\u001b[m           urls_neg.txt    urls_unsup.txt\n"
     ]
    }
   ],
   "source": [
    "! ls ../data/aclImdb/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and assign to the correct class (positive or negative)\n",
    "# Ignore the pre-assigned train/test split\n",
    "\n",
    "data = []\n",
    "data_dirs = [\"../data/aclImdb/train/pos\", \"../data/aclImdb/test/pos\", \"../data/aclImdb/train/neg\", \"../data/aclImdb/test/neg\"]\n",
    "\n",
    "for dir_ in data_dirs:\n",
    "    for file in os.listdir(dir_):\n",
    "        with open(os.path.join(dir_, file), \"r\") as f:\n",
    "            lines = \"\"\n",
    "            for line in f:\n",
    "                lines += line\n",
    "\n",
    "            if \"pos\" in dir_:\n",
    "                class_ = 1\n",
    "            elif \"neg\" in dir_:\n",
    "                class_ = 0\n",
    "\n",
    "            # rating = int(file.split(\"_\")[1][0]) # we won't actually use this for the sentiment analysis task\n",
    "            data.append([class_, lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\"class\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0</td>\n",
       "      <td>Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.&lt;br /&gt;&lt;br /&gt;Branagh steals the film from under Fishburne's nose, and there's a talented cast on good form.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>0</td>\n",
       "      <td>Well...tremors I, the original started off in 1990 and i found the movie quite enjoyable to watch. however, they proceeded to make tremors II and III. Trust me, those movies started going downhill right after they finished the first one, i mean, ass blasters??? Now, only God himself is capable of answering the question \"why in Gods name would they create another one of these dumpster dives of a movie?\" Tremors IV cannot be considered a bad movie, in fact it cannot be even considered an epitome of a bad movie, for it lives up to more than that. As i attempted to sit though it, i noticed that my eyes started to bleed, and i hoped profusely that the little girl from the ring would crawl through the TV and kill me. did they really think that dressing the people who had stared in the other movies up as though they we're from the wild west would make the movie (with the exact same occurrences) any better? honestly, i would never suggest buying this movie, i mean, there are cheaper ways to find things that burn well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>0</td>\n",
       "      <td>Ouch! This one was a bit painful to sit through. It has a cute and amusing premise, but it all goes to hell from there. Matthew Modine is almost always pedestrian and annoying, and he does not disappoint in this one. Deborah Kara Unger and John Neville turned in surprisingly decent performances. Alan Bates and Jennifer Tilly, among others, played it way over the top. I know that's the way the parts were written, and it's hard to blame actors, when the script and director have them do such schlock. If you're going to have outrageous characters, that's OK, but you gotta have good material to make it work. It didn't here. Run away screaming from this movie if at all possible.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "25000  0       \n",
       "25001  0       \n",
       "25002  0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \n",
       "25000  Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.<br /><br />Branagh steals the film from under Fishburne's nose, and there's a talented cast on good form.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "25001  Well...tremors I, the original started off in 1990 and i found the movie quite enjoyable to watch. however, they proceeded to make tremors II and III. Trust me, those movies started going downhill right after they finished the first one, i mean, ass blasters??? Now, only God himself is capable of answering the question \"why in Gods name would they create another one of these dumpster dives of a movie?\" Tremors IV cannot be considered a bad movie, in fact it cannot be even considered an epitome of a bad movie, for it lives up to more than that. As i attempted to sit though it, i noticed that my eyes started to bleed, and i hoped profusely that the little girl from the ring would crawl through the TV and kill me. did they really think that dressing the people who had stared in the other movies up as though they we're from the wild west would make the movie (with the exact same occurrences) any better? honestly, i would never suggest buying this movie, i mean, there are cheaper ways to find things that burn well.  \n",
       "25002  Ouch! This one was a bit painful to sit through. It has a cute and amusing premise, but it all goes to hell from there. Matthew Modine is almost always pedestrian and annoying, and he does not disappoint in this one. Deborah Kara Unger and John Neville turned in surprisingly decent performances. Alan Bates and Jennifer Tilly, among others, played it way over the top. I know that's the way the parts were written, and it's hard to blame actors, when the script and director have them do such schlock. If you're going to have outrageous characters, that's OK, but you gotta have good material to make it work. It didn't here. Run away screaming from this movie if at all possible.                                                                                                                                                                                                                                                                                                                                                          "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at some bad reviews\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df[df[\"class\"] == 0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV's \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina's pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles &amp; Beverly D'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary's Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Einstein, was wonderful. My favorite part, and the only thing that would make me go out of my way to see this again, was the wonderful scene with the physicists playing badmitton, I loved the sweaters and the conversation while they waited for Robbins to retrieve the birdie.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0  1       \n",
       "1  1       \n",
       "2  1       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \n",
       "0  For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "1  Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV's \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina's pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary's Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****  \n",
       "2  A solid, if unremarkable film. Matthau, as Einstein, was wonderful. My favorite part, and the only thing that would make me go out of my way to see this again, was the wonderful scene with the physicists playing badmitton, I loved the sweaters and the conversation while they waited for Robbins to retrieve the birdie.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good reviews.\n",
    "df[df[\"class\"] == 1].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_document(document):\n",
    "    # Normalize the text.\n",
    "    document = document.lower()\n",
    "\n",
    "    # Remove non-alphanumeric characters.\n",
    "    document = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", document)\n",
    "    \n",
    "    # Remove sequences of whitespace.\n",
    "    document = re.sub(r\" +\", r\" \", document)\n",
    "    \n",
    "    # Strip trailing newline characters.\n",
    "    document = document.strip()\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(pre_process_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem imagine a movie where joe piscopo is actually funny maureen stapleton is a scene stealer the moroni character is an absolute scream watch for alan the skipper hale jr as a police sgt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bizarre horror movie filled with famous faces but stolen by cristina raines later of tvs flamingo road as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the gateway to hell the scenes with raines modeling are very well captured the mood music is perfect deborah raffin is charming as cristinas pal but when raines moves into a creepy brooklyn heights brownstone inhabited by a blind priest on the top floor things really start cooking the neighbors including a fantastically wicked burgess meredith and kinky couple sylvia miles beverly dangelo are a diabolical lot and eli wallach is great fun as a wily police detective the movie is nearly a crosspollination of rosemarys baby and the exorcistbut what a combination based on the bestseller by jeffrey konvitz the sentinel is entertainingly spooky full of shocks brought off well by director michael winner who mounts a thoughtfully downbeat ending with skill 12 from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a solid if unremarkable film matthau as einstein was wonderful my favorite part and the only thing that would make me go out of my way to see this again was the wonderful scene with the physicists playing badmitton i loved the sweaters and the conversation while they waited for robbins to retrieve the birdie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0  1       \n",
       "1  1       \n",
       "2  1       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "0  for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem imagine a movie where joe piscopo is actually funny maureen stapleton is a scene stealer the moroni character is an absolute scream watch for alan the skipper hale jr as a police sgt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "1  bizarre horror movie filled with famous faces but stolen by cristina raines later of tvs flamingo road as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the gateway to hell the scenes with raines modeling are very well captured the mood music is perfect deborah raffin is charming as cristinas pal but when raines moves into a creepy brooklyn heights brownstone inhabited by a blind priest on the top floor things really start cooking the neighbors including a fantastically wicked burgess meredith and kinky couple sylvia miles beverly dangelo are a diabolical lot and eli wallach is great fun as a wily police detective the movie is nearly a crosspollination of rosemarys baby and the exorcistbut what a combination based on the bestseller by jeffrey konvitz the sentinel is entertainingly spooky full of shocks brought off well by director michael winner who mounts a thoughtfully downbeat ending with skill 12 from  \n",
       "2  a solid if unremarkable film matthau as einstein was wonderful my favorite part and the only thing that would make me go out of my way to see this again was the wonderful scene with the physicists playing badmitton i loved the sweaters and the conversation while they waited for robbins to retrieve the birdie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_val = train_test_split(df, test_size=0.4)\n",
    "val, test = train_test_split(test_val, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (4000, 2), (16000, 2))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = train[\"text\"], val[\"text\"], test[\"text\"]\n",
    "y_train, y_val, y_test = train[\"class\"], val[\"class\"], test[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "vocab_size = 3000\n",
    "\n",
    "# Stanford was nice enough to give us the vocab.\n",
    "with open(\"../data/aclimdb/imdb.vocab\", \"r\") as f:\n",
    "    for line in f:\n",
    "        vocab.append(line.strip())\n",
    "\n",
    "# Map each vocabulary item to an integer between 1 and vocab_size\n",
    "vocab_vector_map = {}\n",
    "for index, word in enumerate(vocab[:vocab_size]): # only use the 4000 most common words\n",
    "    vocab_vector_map[word] = index + 1 # reserve 0 for padding\n",
    "    \n",
    "def map_vectors(reviews):\n",
    "    mapped_reviews = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        mapped_review = []\n",
    "        for word in review.split(\" \"):\n",
    "            try:\n",
    "                mapped_review.append(vocab_vector_map[word])\n",
    "            except:\n",
    "                pass\n",
    "        mapped_reviews.append(mapped_review)\n",
    "    return mapped_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Map the words in each document to its numerical representation.\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 300\n",
    "X_train2 = sequence.pad_sequences(map_vectors(X_train), maxlen=max_words)\n",
    "X_val2 = sequence.pad_sequences(map_vectors(X_val), maxlen=max_words)\n",
    "X_test2 = sequence.pad_sequences(map_vectors(X_test), maxlen=max_words)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    8,   24,   85,  138,   13,\n",
       "          3,  333,  153, 1333,   32,   11,    6,   29,    4, 1285,   15,\n",
       "          2,  137,   15,   32, 1264,    4,    3,  952,    1,   18,    6,\n",
       "        522,    2,    4,    3, 1617,  266,  288,  173,   13,   72,   13,\n",
       "          3,  853,   80,   31,   11,  922,  117,    5,   32,  874,  506,\n",
       "         13,    3, 1484, 1267, 2014, 1177,    2,   53, 2286,   90,  325,\n",
       "        603, 1092,    6,  253,  337,   24,  358,    4,    1,  967, 2060,\n",
       "        169, 2273,  254,   13, 2140,    3,  601,    2,  311,   33,  638,\n",
       "          8,    1,   88,    4,    3,  180, 1503,  754, 2476,  902,   22,\n",
       "        879,    8,    1,   30,    3, 1039,  114,   22,    1,    4,  845,\n",
       "        291,    5,   24, 1761,    5,    1,  210,  952,   11,   24,  311,\n",
       "       2490, 2901, 2229, 2140,  603,    5,  469,    3,  158,  117,    6,\n",
       "         31,    1, 1052,    4, 1279,   24,  311,   32,   14, 2476,   60,\n",
       "       1074,  796,   87,    5,  373,    1,    2,    4,  109,    3,  601,\n",
       "          5,   24,  308,    2,   50,    5,   87,    3,   49,  311,    5,\n",
       "         24,  465,  247,   31,    1,  579, 1333,  510,    6,  139,    4,\n",
       "          3,    8,  333,  108,   15,    1, 1345,    4, 1274,    5,  228,\n",
       "         90,    8,  106,  210,  450,   81,    3, 1378, 2399,    4,   11,\n",
       "          6,  553,    8,  334,   90,   27,   11,   77,   90,    2,   14,\n",
       "       2024,    5,  211], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at an encoded document\n",
    "X_train2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 in his first go as a hollywood director henry an that is all of issues with and such with an equally of a business the film is directed and of a wonderfully put together cast as well as a screenplay also by that brings life to an otherwise genre as a delivers subtle unexpected charming and very welcome its star whose state is especially given his line of the william h again captures our as alex a husband and father who finds in the most of a young attractive named sarah whom he meets in the at a office where he the of dr john to his growing to the family business that his father donald sutherland built alex whose to lead a new life is by the fear of disappointing his father an for sarah which ultimately leads him to understand the and of being a husband to his wife and more to him a good father to his son played by the david henry brilliant is something of a in hollywood seen with the exception of road to since its in two family drama into a fascinating warm of that is strong in either its one that will its and for ages to come'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure the transformation was correct.\n",
    "reversed_map = {v: k for k, v in vocab_vector_map.items()}\n",
    "reversed_map[0] = \"0\"\n",
    "\n",
    "decoded = [reversed_map[i] for i in X_train2[0]]\n",
    "\" \".join(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1: Simple model (RNN)\n",
    "LSTM with embedding layer. Each document is reduced to 300 words. Documents with less than this # are zero-padded. An embedding layer of 32 dimensions is added, so this layer's output is (data, 400, 32). This is then fed to an LSTM with output of (data, 100). Then a dense layer with shape (data, 1) is added (binary classification). Word embeddings are being learned during training, so during classification the embedding layer serves as a pre-processer. In `V2` I will use pretrained embeddings to see if performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_74 (Embedding)     (None, 300, 32)           96032     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 149,333\n",
      "Trainable params: 149,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the simple model with our custom embedding layer.\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "embedding_dim=32\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size + 1, embedding_dim, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "patience = 50\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"../models/doc_classif/doc_classif_v1.{epoch:02d}-{val_acc:.2f}.model\",\n",
    "                                   \"val_loss\", verbose=1, save_best_only=True)\n",
    "callbacks = [model_checkpoint, early_stop, reduce_lr]\n",
    " \n",
    "model.fit(X_train2, y_train, validation_data=(X_val2, y_val), batch_size=64, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 79s 5ms/sample - loss: 0.2374 - acc: 0.9093\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# The second epoch of the model (out of 50) was already the best-performing, at 86% accuracy.\n",
    "model = load_model(\"../models/doc_classif/doc_classif_v1.02-0.86.model\")\n",
    "\n",
    "score = model.evaluate(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy is: 0.909\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model's accuracy is: {score[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the embeddings make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what the word embeddings look like\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.layers[0].output)\n",
    "intermediate_output = intermediate_layer_model.predict(X_test2[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a word embedding\n",
    "word_id = reversed_map[X_test2[0, -1]]\n",
    "word_embed_1 = intermediate_output[0, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('video',\n",
       " array([ 0.00781669, -0.05589531,  0.01132666, -0.0148676 ,  0.03820979,\n",
       "        -0.02667308, -0.00871681,  0.02055935,  0.00824991,  0.02728681,\n",
       "        -0.01356855,  0.01657996, -0.0638892 , -0.03288768,  0.00123704,\n",
       "        -0.05473331,  0.02520202,  0.01562783,  0.05673045,  0.02553965,\n",
       "         0.01083835, -0.0684996 , -0.05392539, -0.02837973, -0.00661056,\n",
       "        -0.00187142,  0.05335394,  0.05562951, -0.01034331,  0.00165773,\n",
       "        -0.01067892, -0.00635923], dtype=float32))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id, word_embed_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2: Simple Model (CNN)\n",
    "Let's see if I can get a higher accuracy with a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_89 (Embedding)     (None, 300, 32)           96032     \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 148, 32)           5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 24, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                24608     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 125,825\n",
      "Trainable params: 125,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, ReLU, MaxPool1D, Dense, Flatten\n",
    "\n",
    "# Define the model hyperparameters.\n",
    "kernel_size = 5\n",
    "stride_size = 2\n",
    "\n",
    "# Define the model.\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size + 1, embedding_dim, input_length=max_words))\n",
    "\n",
    "model.add(Conv1D(embedding_dim, kernel_size=kernel_size, activation=\"relu\", strides=stride_size))\n",
    "model.add(MaxPool1D(6))\n",
    "\n",
    "# model.add(Conv1D(embedding_dim, kernel_size=kernel_size, activation=\"relu\", strides=stride_size))\n",
    "# model.add(MaxPool1D(5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(embedding_dim, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.7503\n",
      "Epoch 00001: val_loss improved from inf to 0.36244, saving model to ../models/doc_classif/doc_classif_v2.01-0.86.model\n",
      "30000/30000 [==============================] - 19s 645us/sample - loss: 0.4841 - acc: 0.7509 - val_loss: 0.3624 - val_acc: 0.8565\n",
      "Epoch 2/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8859\n",
      "Epoch 00002: val_loss improved from 0.36244 to 0.34185, saving model to ../models/doc_classif/doc_classif_v2.02-0.86.model\n",
      "30000/30000 [==============================] - 14s 452us/sample - loss: 0.2911 - acc: 0.8860 - val_loss: 0.3418 - val_acc: 0.8635\n",
      "Epoch 3/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.2483 - acc: 0.9074\n",
      "Epoch 00003: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 13s 448us/sample - loss: 0.2481 - acc: 0.9075 - val_loss: 0.3654 - val_acc: 0.8568\n",
      "Epoch 4/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9257\n",
      "Epoch 00004: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 14s 454us/sample - loss: 0.2097 - acc: 0.9257 - val_loss: 0.4023 - val_acc: 0.8482\n",
      "Epoch 5/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9461\n",
      "Epoch 00005: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 14s 453us/sample - loss: 0.1713 - acc: 0.9462 - val_loss: 0.4299 - val_acc: 0.8515\n",
      "Epoch 6/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9646\n",
      "Epoch 00006: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 14s 454us/sample - loss: 0.1319 - acc: 0.9646 - val_loss: 0.4696 - val_acc: 0.8500\n",
      "Epoch 7/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9784\n",
      "Epoch 00007: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 14s 453us/sample - loss: 0.1004 - acc: 0.9784 - val_loss: 0.5676 - val_acc: 0.8438\n",
      "Epoch 8/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9866\n",
      "Epoch 00008: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 14s 452us/sample - loss: 0.0785 - acc: 0.9866 - val_loss: 0.6399 - val_acc: 0.8420\n",
      "Epoch 9/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9934\n",
      "Epoch 00009: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 14s 451us/sample - loss: 0.0597 - acc: 0.9934 - val_loss: 0.6994 - val_acc: 0.8430\n",
      "Epoch 10/10\n",
      "29888/30000 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9961\n",
      "Epoch 00010: val_loss did not improve from 0.34185\n",
      "30000/30000 [==============================] - 13s 447us/sample - loss: 0.0495 - acc: 0.9961 - val_loss: 0.7229 - val_acc: 0.8393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b114f0080>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks.\n",
    "patience = 50\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"../models/doc_classif/doc_classif_v2.{epoch:02d}-{val_acc:.2f}.model\",\n",
    "                                   \"val_loss\", verbose=1, save_best_only=True)\n",
    "callbacks = [model_checkpoint, early_stop, reduce_lr]\n",
    " \n",
    "model.fit(X_train2, y_train, validation_data=(X_val2, y_val), batch_size=64, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"../models/doc_classif/doc_classif_v2.01-0.76.model\")\n",
    "\n",
    "score = model.evaluate(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is clearly overfitting!\n",
    "print(f\"The model's accuracy is: {score[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.layers[0].output)\n",
    "intermediate_output = intermediate_layer_model.predict(X_test2[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a word embedding\n",
    "word_id = reversed_map[X_test2[0, -1]]\n",
    "word_embed_2 = intermediate_output[0, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11223558,  0.08183846,  0.01147118, -0.01565666,  0.00983325,\n",
       "        0.09597315,  0.09680772, -0.02314371,  0.07450233, -0.13953364,\n",
       "        0.01541835, -0.02070905,  0.10246259,  0.00691553,  0.00536317,\n",
       "        0.07562193, -0.02554925, -0.05911353, -0.11711088,  0.00868019,\n",
       "        0.02955585,  0.10348634, -0.0146784 ,  0.0522786 , -0.01883752,\n",
       "        0.0121856 , -0.01050882, -0.0756413 ,  0.07307447, -0.01438064,\n",
       "        0.07249837,  0.00597489], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the embeddings that the RNN and CNN learned are simikar, this should be close to 0. That's not the case!\n",
    "word_embed_2 - word_embed_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2: Training an embedding layer using Glove\n",
    "Same as **V1** except that the embeddings are trained using glove. These are then fed to the RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V3a: Simple model + pretrained embeddings\n",
    "Same as **V1** except that pretrained embeddings are used. Glove embeddings used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V3b: Simple model + pretrained embeddings\n",
    "Same as **V1** except that pretrained embeddings are used. Elmo embeddings used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
